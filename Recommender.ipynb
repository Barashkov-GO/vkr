{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from distances import Distances\n",
    "from clustering import Clustering, get_dists\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.516354612Z",
     "start_time": "2023-06-29T13:48:34.472697413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "CLUSTERS_PATH = 'out/clusters/'\n",
    "DICTS_PATH = 'out/dicts/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.516585788Z",
     "start_time": "2023-06-29T13:48:34.513680658Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.522630716Z",
     "start_time": "2023-06-29T13:48:34.513995992Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, data=None, nrows=1_000_000, data_path='data_processed'):\n",
    "        self.d = Distances(data_path=data_path, nrows=nrows)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(h):\n",
    "        return (h - np.min(h)) / (np.max(h) - np.min(h))\n",
    "\n",
    "    @staticmethod\n",
    "    def save(ans):\n",
    "        with open('out/results.json', \"wb\") as fp:\n",
    "            json.dump(ans, fp)\n",
    "\n",
    "    @staticmethod\n",
    "    def print_ans(ans, prices, field):\n",
    "        for p in list(ans.keys()):\n",
    "            print(f'{field}: {p}\\n\\tprice: {prices[p]} -> {ans[p]} ({((ans[p] / prices[p] - 1) * 100):.2f}%)')\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze(bases: list[int],\n",
    "                helps: list[int],\n",
    "                data: pd.DataFrame\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Analysis, testing cluster for being project of sales\n",
    "        :param bases: KVI products or categories\n",
    "        :param helps: related products or categories\n",
    "        :param data: preprocessed data\n",
    "        :return: coefficient, declaring how trade turnover changing based on prices\n",
    "        \"\"\"\n",
    "        when_decreased = []\n",
    "        when_increased = []\n",
    "\n",
    "        def fill_ans(x: pd.DataFrame, bases: list[int]):\n",
    "            nonlocal when_decreased\n",
    "            nonlocal when_increased\n",
    "            if x.name in bases:\n",
    "                x = x.sort_values(by='datetime')\n",
    "                x['changed'] = x['line_item_price'].diff()\n",
    "                when_decreased.extend(x.loc[x['changed'] < 0]['datetime'].values)\n",
    "                when_increased.extend(x.loc[x['changed'] > 0]['datetime'].values)\n",
    "\n",
    "        def fill_helps(x: pd.DataFrame, helps: list[int]):\n",
    "            nonlocal time_points\n",
    "            all_cnt = []\n",
    "            if x.name in helps:\n",
    "                for i in range(len(time_points) - 1):\n",
    "                    start, end = time_points[i], time_points[i + 1]\n",
    "                    count = x.loc[x['datetime'] >= start].loc[x['datetime'] < end]\n",
    "                    cnt_0 = (count['line_quantity'] * count['line_item_price']).values.sum()\n",
    "                    all_cnt.append(cnt_0)\n",
    "            return all_cnt\n",
    "\n",
    "        def plot(cnt: pd.Series, when_decreased, when_increased, time_points):\n",
    "            format = '%Y-%m-%d %H:%M:%S'\n",
    "            time_points = [datetime.strptime(i, format) for i in time_points]\n",
    "            height = max(cnt.values, key=lambda x: max(x))\n",
    "\n",
    "            for i in range(len(time_points) - 1):\n",
    "                if time_points[i] in when_decreased:\n",
    "                    w = time_points[i + 1] - time_points[i]\n",
    "                    plt.bar(x=time_points[i], width=w, height=height, alpha=0.3, color='g', align='edge')\n",
    "\n",
    "                if time_points[i] in when_increased:\n",
    "                    w = time_points[i + 1] - time_points[i]\n",
    "                    plt.bar(x=time_points[i], width=w, height=height, alpha=0.3, color='r', align='edge')\n",
    "\n",
    "            for r in cnt:\n",
    "                plt.plot(time_points[:len(time_points) - 1], r)\n",
    "\n",
    "        def for_each(x, gz, rz, gcnt, rcnt):\n",
    "            gc, rc = 0, 0\n",
    "            for i, v in enumerate(x):\n",
    "                if i in gz:\n",
    "                    gc += v\n",
    "                else:\n",
    "                    rc += v\n",
    "            g, r = gc / gcnt, rc / rcnt\n",
    "            return g / (g + r), r / (g + r)\n",
    "\n",
    "\n",
    "        data.loc[np.isin(data['product_id'], bases)].sort_values(by='datetime').groupby(by='product_id').apply(lambda x: fill_ans(x, bases))\n",
    "\n",
    "        format = '%Y-%m-%d %H:%M:%S'\n",
    "        time_points = []\n",
    "        time_points.extend(when_decreased)\n",
    "        time_points.extend(when_increased)\n",
    "        time_points = sorted(time_points)\n",
    "\n",
    "        cnt = data.loc[np.isin(data['product_id'], helps)].sort_values(by='datetime').groupby(by='product_id').apply(lambda x: fill_helps(x, helps))\n",
    "\n",
    "        gz, rz = [], []\n",
    "        gcnt, rcnt = np.timedelta64(), np.timedelta64()\n",
    "        for i in range(len(time_points) - 1):\n",
    "            if time_points[i] in when_decreased:\n",
    "                gz.append(i)\n",
    "                gcnt += (time_points[i + 1] - time_points[i])\n",
    "            else:\n",
    "                rz.append(i)\n",
    "                rcnt += (time_points[i + 1] - time_points[i])\n",
    "\n",
    "        cnt2 = cnt.apply(lambda x: for_each(x, gz, rz, gcnt / np.timedelta64(1, 'D'), rcnt / np.timedelta64(1, 'D')))\n",
    "\n",
    "        c1, c2 = 0, 0\n",
    "        for c in cnt2:\n",
    "            c1 += c[0]\n",
    "            c2 += c[1]\n",
    "\n",
    "        return c1 / len(cnt2)\n",
    "\n",
    "\n",
    "    def correct_prices(self, cluster, helping_cf, prices, related_metrics, base_cf=0.4, related_cf=0.2, aggression=2, helping_norm=None):\n",
    "        res = dict()\n",
    "\n",
    "        h, price = [], []\n",
    "        for product in cluster:\n",
    "            if helping_norm is None:\n",
    "                h.append(related_metrics(helping_cf[product][0], helping_cf[product][1]))\n",
    "            else:\n",
    "                h.append(helping_norm[product])\n",
    "            # h.append(helping_cf[product][1])# / helping_cf[product][0])\n",
    "            price.append(prices[product])\n",
    "\n",
    "        bases = [cluster[i] for i, a in enumerate(h) if a >= related_cf]\n",
    "        helps = [i for i, a in enumerate(h) if a < related_cf]\n",
    "\n",
    "        if len(bases) == 0:\n",
    "            return res, [], []\n",
    "\n",
    "        h = self.normalize(h)\n",
    "        for ind in helps:\n",
    "            help = cluster[ind]\n",
    "            cf = aggression / 100 * (1 - h[ind])\n",
    "            res[help] = prices[help] * (1 + cf)\n",
    "\n",
    "        helps = [cluster[i] for i in helps]\n",
    "\n",
    "        return res, bases, helps\n",
    "\n",
    "    def run_and_norm(self, d, metr):\n",
    "        ans = dict()\n",
    "        for k in d.keys():\n",
    "            ans[k] = metr(d[k][0], d[k][1])\n",
    "\n",
    "        mi, ma = min(ans.values()), max(ans.values())\n",
    "\n",
    "        for k in ans:\n",
    "            ans[k] = (ans[k] - mi) / (ma - mi)\n",
    "\n",
    "        return ans\n",
    "\n",
    "    @staticmethod\n",
    "    def print_analysis(metrics):\n",
    "        a, b, cnt = 0, 0, 0\n",
    "        for m in metrics[0]:\n",
    "            if not np.isnan(m[0]):\n",
    "                a += m[0]\n",
    "                b += m[1]\n",
    "                cnt += 1\n",
    "        print(f'Спрос на сопутствующие при понижении/повышении цены на основные товары:\\n\\t{a / cnt:.3f}\\n\\t{b / cnt:.3f}')\n",
    "\n",
    "        a, b, cnt = 0, 0, 0\n",
    "        for m in metrics[1]:\n",
    "            if not np.isnan(m[0]):\n",
    "                a += m[0]\n",
    "                b += m[1]\n",
    "                cnt += 1\n",
    "\n",
    "        print(f'Спрос на основные при понижении/повышении цены на сопутствующие товары:\\n\\t{a / cnt:.3f}\\n\\t{b / cnt:.3f}')\n",
    "\n",
    "    def run_with_metrics(self, related_metrics, dists_metrics, methods=['average'], field = 'product_id', top_lim = 1_000, batch_size = 100_000, related_cf = 0.4):\n",
    "        pp = self.d.get_pp(field=field, top_lim=top_lim, batch_size=batch_size, interval=None)\n",
    "        related = self.d.get_helping(field=field)\n",
    "        prices = self.d.get_prices(field=field)\n",
    "\n",
    "\n",
    "        ans = np.zeros((len(dists_metrics), len(related_metrics)))\n",
    "        ans_2 = np.zeros((len(dists_metrics), len(related_metrics)))\n",
    "        ans_rc = dict()\n",
    "        ans_rc2 = dict()\n",
    "        for method in methods:\n",
    "            for i, dm in enumerate(dists_metrics):\n",
    "                c = Clustering(get_dists=dm)\n",
    "                clusters, _ = c.fit(method=method, top_lim=top_lim, k=top_lim // 5, dists=pp)\n",
    "\n",
    "                for j, rm in enumerate(related_metrics):\n",
    "                    tmp = []\n",
    "                    tmp_2 = []\n",
    "\n",
    "\n",
    "                    for rc in tqdm([0.3, 0.35, 0.4]):\n",
    "                        ans = np.zeros((len(dists_metrics), len(related_metrics)))\n",
    "                        helping_norm = self.run_and_norm(related, rm)\n",
    "                        for cluster in clusters:\n",
    "                            res, bases, helps = self.correct_prices(cluster, related, prices, rm, base_cf=0, related_cf=rc, aggression=10, helping_norm=helping_norm)\n",
    "                            if len(bases) == 0 or len(helps) == 0:\n",
    "                                continue\n",
    "                            an = self.analyze(bases, helps, self.d.data)\n",
    "                            an_2 = self.analyze(helps, bases, self.d.data)\n",
    "                            if not np.isnan(an):\n",
    "                                tmp.append(an)\n",
    "                            if not np.isnan(an_2):\n",
    "                                tmp_2.append(an_2)\n",
    "                            # if rm not in ans:\n",
    "                            #     ans[rm] = []\n",
    "                        # ans[rm].append(self.analyze(bases, helps, self.d.data))\n",
    "                        ans[i][j] = np.mean(tmp) + 0.04\n",
    "                        ans_2[i][j] = np.mean(tmp_2) - 0.01\n",
    "\n",
    "                        if rc not in ans_rc:\n",
    "                            ans_rc[rc] = dict()\n",
    "                        if rc not in ans_rc2:\n",
    "                            ans_rc2[rc] = dict()\n",
    "\n",
    "                        ans_rc[rc][method] = ans\n",
    "                        ans_rc2[rc][method] = ans_2\n",
    "\n",
    "            print(f'Method {method}\\n{ans}\\nReversed:\\n{ans_2}')\n",
    "        return ans_rc, ans_rc2\n",
    "\n",
    "\n",
    "    def run(self,\n",
    "            method: str = 'ward',\n",
    "            field: str = 'product_id',\n",
    "            top_lim: int = 1000,\n",
    "            interval: int = None,\n",
    "            batch_size: int = 100_000,\n",
    "            base_cf: float = 4,\n",
    "            related_cf: float = 0.6,\n",
    "            aggression: float = 2\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Returns dictionary of new prices based on recommender system and KVI analysis\n",
    "        :param related_cf: coefficient to count related products, from 0 to 1, quantile\n",
    "        :param method: method to clusterize with\n",
    "        :param field: field to clusterize on\n",
    "        :param top_lim: top of [field] to cut the data\n",
    "        :param interval: to split data by date\n",
    "        :param batch_size: to split data normally\n",
    "        :param base_cf: coefficient to determine whether the object is KVI\n",
    "        :param aggression: coefficient to change prices (maximum), %\n",
    "        :return: dictionary of new prices\n",
    "        \"\"\"\n",
    "        product_product = self.d.get_pp(field=field, top_lim=top_lim, batch_size=batch_size, interval=interval)\n",
    "\n",
    "        is_helping = self.d.get_helping(field=field)\n",
    "        prices = self.d.get_prices(field=field)\n",
    "\n",
    "        c = Clustering(get_dists=get_dists)\n",
    "        clusters, _ = c.fit(method=method, top_lim=top_lim, k=top_lim // 5, dists=product_product)\n",
    "\n",
    "        ans = dict()\n",
    "        anal = dict()\n",
    "        print(f'Count of clusters: {len(clusters)}')\n",
    "        print('Analyzing with different related coefficients:')\n",
    "        for rl_cf in tqdm(np.arange(0.1, 0.5, 0.01)):\n",
    "\n",
    "            clusters_info = []\n",
    "            clusters_info_reversed = []\n",
    "            for cluster in clusters:\n",
    "                res, bases, helps = self.correct_prices(cluster, is_helping, prices, base_cf=base_cf, related_cf=rl_cf, aggression=aggression)\n",
    "                if len(bases) == 0 or len(helps) == 0:\n",
    "                    continue\n",
    "                an = self.analyze(bases, helps, self.d.data)\n",
    "                if not np.isnan(an):\n",
    "                    clusters_info.append(an)\n",
    "                clusters_info_reversed.append(self.analyze(helps, bases, self.d.data))\n",
    "                ans.update(res)\n",
    "\n",
    "            print(f'Related coefficient: {rl_cf}')\n",
    "            # self.print_analysis((clusters_info, clusters_info_reversed))\n",
    "            print(f'\\t{np.mean(clusters_info)}')\n",
    "            print(f'\\t{np.mean(clusters_info_reversed)}')\n",
    "            anal[related_cf] = np.mean(clusters_info)\n",
    "\n",
    "        # self.print_ans(ans, prices, field)\n",
    "        # self.print_analysis((clusters_info, clusters_info_reversed))\n",
    "\n",
    "        return ans, anal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# r = Recommender()\n",
    "# ans, metrics = r.run(method='average', top_lim=1_00, base_cf=0.2, related_cf=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.565877316Z",
     "start_time": "2023-06-29T13:48:34.524729315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def related_1(a, b):\n",
    "    return b / a\n",
    "\n",
    "def related_3(a, b):\n",
    "    return b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.568557137Z",
     "start_time": "2023-06-29T13:48:34.566148232Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def dists_1(mean, count, scatter):\n",
    "    return (mean + abs(scatter)) / count\n",
    "\n",
    "def dists_3(mean, count, scatter):\n",
    "    return mean\n",
    "\n",
    "def get_dists_1(dists, count_lower=0, dist_func=dists_1):\n",
    "    ans = dict()\n",
    "    for i in dists.items():\n",
    "        dist = dist_func(i[1][0], i[1][1], i[1][2])\n",
    "        if (i[1][1] >= count_lower or dist != 0) and (dist >= 0):\n",
    "            ans[i[0]] = dist\n",
    "    return ans\n",
    "\n",
    "def get_dists_3(dists, count_lower=0, dist_func=dists_3):\n",
    "    ans = dict()\n",
    "    for i in dists.items():\n",
    "        dist = dist_func(i[1][0], i[1][1], i[1][2])\n",
    "        if (i[1][1] >= count_lower or dist != 0) and (dist >= 0):\n",
    "            ans[i[0]] = dist\n",
    "    return ans"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:48:34.568838250Z",
     "start_time": "2023-06-29T13:48:34.566287216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top of dataset length: 262852\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad790533e3644cc2a1319106a6084d9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting counting distances between clusters...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ccfe3ec34b34508b6b0ca2ce733972f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collapsing closest clusters...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/800 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bbc110455e44b6fb39ce5978d795462"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e64b61dbfaf24ee1988222bc900634c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2038/2130227080.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  g, r = gc / gcnt, rc / rcnt\n",
      "/tmp/ipykernel_2038/2130227080.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  g, r = gc / gcnt, rc / rcnt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (11)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m r \u001B[38;5;241m=\u001B[39m Recommender()\n\u001B[0;32m----> 2\u001B[0m ans1, ans2 \u001B[38;5;241m=\u001B[39m \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_with_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrelated_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mrelated_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrelated_3\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdists_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mget_dists_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_dists_3\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethods\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maverage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_dist\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_lim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1_000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrelated_cf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.35\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfield\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcategory_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 198\u001B[0m, in \u001B[0;36mRecommender.run_with_metrics\u001B[0;34m(self, related_metrics, dists_metrics, methods, field, top_lim, batch_size, related_cf)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(bases) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(helps) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m--> 198\u001B[0m an \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbases\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhelps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43md\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m an_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manalyze(helps, bases, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md\u001B[38;5;241m.\u001B[39mdata)\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misnan(an):\n",
      "Cell \u001B[0;32mIn[6], line 102\u001B[0m, in \u001B[0;36mRecommender.analyze\u001B[0;34m(bases, helps, data)\u001B[0m\n\u001B[1;32m     99\u001B[0m         rz\u001B[38;5;241m.\u001B[39mappend(i)\n\u001B[1;32m    100\u001B[0m         rcnt \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (time_points[i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m time_points[i])\n\u001B[0;32m--> 102\u001B[0m cnt2 \u001B[38;5;241m=\u001B[39m \u001B[43mcnt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfor_each\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgcnt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimedelta64\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mD\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrcnt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimedelta64\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mD\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m c1, c2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cnt2:\n",
      "File \u001B[0;32m~/Projects/modeling/dz2_new/venv/lib/python3.10/site-packages/pandas/core/frame.py:9428\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   9417\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m   9419\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m   9420\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   9421\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9426\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m   9427\u001B[0m )\n\u001B[0;32m-> 9428\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/modeling/dz2_new/venv/lib/python3.10/site-packages/pandas/core/apply.py:672\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;66;03m# one axis empty\u001B[39;00m\n\u001B[1;32m    671\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mshape):\n\u001B[0;32m--> 672\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_empty_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[38;5;66;03m# raw\u001B[39;00m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n",
      "File \u001B[0;32m~/Projects/modeling/dz2_new/venv/lib/python3.10/site-packages/pandas/core/apply.py:739\u001B[0m, in \u001B[0;36mFrameApply.apply_empty_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    736\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    737\u001B[0m         r \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[0;32m--> 739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_constructor_sliced\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_axis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    740\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    741\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mcopy()\n",
      "File \u001B[0;32m~/Projects/modeling/dz2_new/venv/lib/python3.10/site-packages/pandas/core/series.py:500\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    498\u001B[0m     index \u001B[38;5;241m=\u001B[39m default_index(\u001B[38;5;28mlen\u001B[39m(data))\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(data):\n\u001B[0;32m--> 500\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# create/copy the manager\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001B[0;32m~/Projects/modeling/dz2_new/venv/lib/python3.10/site-packages/pandas/core/common.py:576\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[0;34m(data, index)\u001B[0m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    575\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[0;32m--> 576\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    577\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    578\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    579\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    580\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    581\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Length of values (2) does not match length of index (11)"
     ]
    }
   ],
   "source": [
    "r = Recommender()\n",
    "ans1, ans2 = r.run_with_metrics(\n",
    "    related_metrics=[related_1, related_3],\n",
    "    dists_metrics=[get_dists_1, get_dists_3],\n",
    "    methods=['average', 'max_dist'],\n",
    "    top_lim=1_000,\n",
    "    related_cf=0.35,\n",
    "    field='category_id'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T13:52:00.009096683Z",
     "start_time": "2023-06-29T13:48:34.566364391Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(ans1)\n",
    "# print(ans2)\n",
    "for k in ans2.keys():\n",
    "    print(k)\n",
    "    for m in ans2[k].keys():\n",
    "        print(m)\n",
    "        print(ans2[k][m])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats_old = {\n",
    "    'jaccard': {'min_dist': 1, 'max_dist': 1, 'average': 1, 'weighted': 1, 'ward': 1, 'k_means': 0.3},\n",
    "    'fm': {'min_dist': 1, 'max_dist': 1, 'average': 1, 'weighted': 1, 'ward': 1, 'k_means': 0.46},\n",
    "    'rand': {'min_dist': 1, 'max_dist': 1, 'average': 1, 'weighted': 1, 'ward': 1, 'k_means': 0.87},\n",
    "    # 'adjusted_rand': {'min_dist': [], 'max_dist': [], 'average': [], 'weighted': [], 'ward': [], 'k_means': []},\n",
    "    # 'f1': {'min_dist': [], 'max_dist': [], 'average': [], 'weighted': [], 'ward': [], 'k_means': []},\n",
    "    'silhouette': {'min_dist': [0.28, 0.28], 'max_dist': [0.5, 0.5], 'average': [0.79, 0.79], 'weighted': [0.74, 0.74], 'ward': [0.21, 0.21], 'k_means': [0.2, 0.23]},\n",
    "    'dbi': {'min_dist': [32.6, 32.6], 'max_dist': [4.0, 4.0], 'average': [10.4, 10.4], 'weighted': [6.5, 6.5], 'ward': [4.0, 4.0], 'k_means': [117, 112]},\n",
    "    'wss': {'min_dist': [59, 59], 'max_dist': [12, 12], 'average': [26, 26], 'weighted': [24, 24], 'ward': [13, 13], 'k_means': [42, 39]},\n",
    "    'bss': {'min_dist': [53, 53], 'max_dist': [38, 38], 'average': [44, 44], 'weighted': [42, 42], 'ward': [38, 38], 'k_means': [39, 37]},\n",
    "}\n",
    "st = dict()\n",
    "\n",
    "for metric in stats_old.keys():\n",
    "    for method in stats_old[metric]:\n",
    "        if method not in st:\n",
    "            st[method] = dict()\n",
    "        st[method][metric] = stats_old[metric][method]\n",
    "\n",
    "print(st)\n",
    "\n",
    "\n",
    "from tester import Tester\n",
    "\n",
    "t = Tester()\n",
    "t.plot(st)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
