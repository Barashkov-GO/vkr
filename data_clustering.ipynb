{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:11.752605031Z",
     "start_time": "2023-05-31T02:12:11.752167099Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "DICTS_PATH = 'out/dicts/'\n",
    "CLUSTERS_PATH = 'out/clusters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.802068369Z",
     "start_time": "2023-05-31T02:12:11.752326117Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocesspandas import applyparallel\n",
    "from pandarallel import pandarallel\n",
    "import psutil\n",
    "from sys import getsizeof\n",
    "import networkx as nx\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "from netgraph import Graph, InteractiveGraph, EditableGraph\n",
    "\n",
    "import pickle\n",
    "import gc \n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.808320340Z",
     "start_time": "2023-05-31T02:12:12.806404873Z"
    }
   },
   "outputs": [],
   "source": [
    "def default(mean, count, scatter):\n",
    "    return (mean + abs(scatter)) / (count ** 2)\n",
    "\n",
    "def get_dists(dists, count_lower=10, dist_func=default):\n",
    "    return dict([(i[0], dist_func(i[1][0], i[1][1], i[1][2])) \n",
    "                 for i in dists.items() \n",
    "                 if (i[1][1] >= count_lower\n",
    "                     or dist_func(i[1][0], i[1][1], i[1][2]) != 0) \n",
    "                 and dist_func(i[1][0], i[1][1], i[1][2]) >= 0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.820687385Z",
     "start_time": "2023-05-31T02:12:12.818322864Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, method='euclidean', max=100):\n",
    "        self.method = method\n",
    "        self.max = max\n",
    "\n",
    "    def run(self, cluster1, cluster2, dists):\n",
    "        self.cluster1 = cluster1\n",
    "        self.cluster2 = cluster2\n",
    "        self.dists = dists\n",
    "\n",
    "        if self.method == 'euclidean':\n",
    "            return self.euclidean()\n",
    "        if self.method == 'min_dist':\n",
    "            return self.min_dist()\n",
    "        if self.method == 'max_dist':\n",
    "            return self.max_dist()\n",
    "        if self.method == 'average':\n",
    "            return self.average()\n",
    "        if self.method == 'ward':\n",
    "            return self.ward()\n",
    "\n",
    "    def _get(self, i, j):\n",
    "        if i == j:\n",
    "            return 0.0\n",
    "        if (i, j) in self.dists:\n",
    "            return self.dists[(i, j)]\n",
    "        if (j, i) in self.dists:\n",
    "            return self.dists[(j, i)]\n",
    "        return self.max\n",
    "\n",
    "\n",
    "    def euclidean(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j) ** 2\n",
    "        return np.sqrt(s)\n",
    "\n",
    "\n",
    "    def min_dist(self):\n",
    "        s, mini = 0.0, self.max + 1\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s < mini:\n",
    "                    mini = s\n",
    "        return mini\n",
    "\n",
    "\n",
    "    def max_dist(self):\n",
    "        s, maxi = 0.0, -1.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s > maxi:\n",
    "                    maxi = s\n",
    "        return maxi\n",
    "\n",
    "\n",
    "    def average(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j)\n",
    "        return s / (n1 * n2)\n",
    "\n",
    "\n",
    "    def ward(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s_u, s_1, s_2 = 0.0, 0.0, 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s_u += self._get(i, j) ** 2\n",
    "\n",
    "        for i in range(n1):\n",
    "            for j in range(i + 1, n1):\n",
    "                s_1 += self._get(self.cluster1[i], self.cluster1[j])\n",
    "\n",
    "        for i in range(n2):\n",
    "            for j in range(i + 1, n2):\n",
    "                s_2 += self._get(self.cluster2[i], self.cluster2[j])\n",
    "        return (s_u - s_1 - s_2) / (n1 + n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ClustersDists:\n",
    "    def __init__(self, fill=np.inf):\n",
    "        self.dists = dict()\n",
    "        self.fill = fill\n",
    "\n",
    "    def set(self, i, j, val):\n",
    "        self.dists[i, j] = val\n",
    "\n",
    "    def get(self, i, j):\n",
    "        if (i, j) in self.dists:\n",
    "            return self.dists[i, j]\n",
    "        if (j, i) in self.dists:\n",
    "            return self.dists[j, i]\n",
    "        return self.fill\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.get(key[0], key[1])\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.set(key[0], key[1], value)\n",
    "\n",
    "    def min(self):\n",
    "        return min(self.dists, key=self.dists.get)\n",
    "\n",
    "    def remove(self, i):\n",
    "        keys = list(self.dists.keys())\n",
    "        for key in keys:\n",
    "            if i in key:\n",
    "                self.dists.pop(key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.852965451Z",
     "start_time": "2023-05-31T02:12:12.829417309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.898422086Z",
     "start_time": "2023-05-31T02:12:12.847249066Z"
    }
   },
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, get_dists=get_dists):\n",
    "        self.get_dists = get_dists\n",
    "        self.statistics = {\n",
    "            'min_distances': [],\n",
    "            'time_of_iter': [],\n",
    "            'time_of_all': 0.0,\n",
    "            'count_of_iters': 0.0,\n",
    "            }\n",
    "\n",
    "    def get_stats(self):\n",
    "        self.statistics['time_of_iter'] = np.array(self.statistics['time_of_iter']).mean()\n",
    "        for k in self.statistics.keys():\n",
    "            print(f\"{k} --- {self.statistics[k]}\")\n",
    "        return self.statistics\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_clusters(cluster1, cluster2):\n",
    "        merged_cluster = cluster1 + cluster2\n",
    "        return merged_cluster\n",
    "\n",
    "    def run(self, dists, k):\n",
    "        start0 = datetime.now()\n",
    "\n",
    "        elements = np.unique(list(dists.keys()))[:100_000]\n",
    "        clusters = [[i] for i in elements]\n",
    "        iters = len(elements) - k\n",
    "\n",
    "        clusters_dists = ClustersDists(fill=np.inf)\n",
    "\n",
    "        print('Starting counting distances between clusters...')\n",
    "\n",
    "        # manager = multiprocessing.Manager()\n",
    "        # dists = manager.dict()\n",
    "\n",
    "        for i in tqdm(range(len(clusters))):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                clusters_dists.set(i, j, self.metric.run(clusters[i], clusters[j], dists))\n",
    "\n",
    "        print(getsizeof(clusters_dists))\n",
    "\n",
    "        print('Starting collapsing closest clusters...')\n",
    "        for _ in tqdm(range(iters)):\n",
    "            start = datetime.now()\n",
    "\n",
    "            i, j = clusters_dists.min()\n",
    "            # a = np.argmin(clusters_dists)\n",
    "            # i, j = a // clusters_dists.shape[1], a % clusters_dists.shape[1]\n",
    "\n",
    "            min_distance = clusters_dists[(i, j)]\n",
    "            merged_cluster = self._merge_clusters(clusters[i], clusters[j])\n",
    "            del clusters[j]\n",
    "            del clusters[i]\n",
    "            clusters_dists.remove(i)\n",
    "            clusters_dists.remove(j)\n",
    "\n",
    "            clusters.append(merged_cluster)\n",
    "\n",
    "            j = len(clusters) - 1\n",
    "            for i in range(len(clusters)):\n",
    "                clusters_dists.set(i, j, self.metric.run(clusters[i], clusters[j], dists))\n",
    "\n",
    "            self.statistics['min_distances'].append(min_distance)\n",
    "            self.statistics['time_of_iter'].append(datetime.now() - start)\n",
    "        self.statistics['count_of_iters'] = iters\n",
    "        self.statistics['time_of_all'] = datetime.now() - start0\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def run_k_means(self, dists, k, max_iter=10_000):\n",
    "        # Можно наканпливать minimal_dist, как внутрикластерное расстояние (в агломеративных тоже)\n",
    "        # Можно сохранять среднее расстояние между кластерами и внутри кластеров, чтобы показывать на графике\n",
    "\n",
    "        start0 = datetime.now()\n",
    "        elements = np.unique(sorted(list(dists.keys()))[:25_000])\n",
    "\n",
    "        clusters = np.random.choice(elements, k, replace=False)\n",
    "        elements = elements[~np.isin(elements, clusters)]\n",
    "        clusters = [[c] for c in clusters]\n",
    "\n",
    "\n",
    "        print('Starting elements splitting by clusters...')\n",
    "        for e in tqdm(elements):\n",
    "            minimal_dist = self.metric.max * 5.0\n",
    "            cluster_index = 0\n",
    "            for i, c in enumerate(clusters):\n",
    "                dist = self.metric.run([e], c, dists)\n",
    "                if dist < minimal_dist:\n",
    "                    minimal_dist = dist\n",
    "                    cluster_index = i\n",
    "\n",
    "            clusters[cluster_index].append(e)\n",
    "\n",
    "\n",
    "        print('Starting operating over clusters...')\n",
    "        for _ in tqdm(range(max_iter)):\n",
    "            self.statistics['count_of_iters'] += 1\n",
    "            start = datetime.now()\n",
    "            prev_clusters = clusters.copy()\n",
    "            for c1 in clusters:\n",
    "                for pos_el, el in enumerate(c1):\n",
    "                    minimal_dist = self.metric.max * 5.0\n",
    "                    cluster_index = 0\n",
    "                    for i, c in enumerate(clusters):\n",
    "                        dist = self.metric.run([el], c, dists)\n",
    "                        if dist < minimal_dist:\n",
    "                            minimal_dist = dist\n",
    "                            cluster_index = i\n",
    "\n",
    "                    self.statistics['min_distances'].append(minimal_dist)\n",
    "\n",
    "                    del c1[pos_el]\n",
    "                    clusters[cluster_index].append(el)\n",
    "\n",
    "            if prev_clusters == clusters:\n",
    "                print('Clusters stabilizied!')\n",
    "                self.statistics['time_of_all'] = datetime.now() - start0\n",
    "                return clusters\n",
    "\n",
    "            self.statistics['time_of_iter'].append(datetime.now() - start)\n",
    "\n",
    "        print('Stopped for maximum iterations: {}'.format(max_iter))\n",
    "        self.statistics['time_of_all'] = datetime.now() - start0\n",
    "        return clusters\n",
    "\n",
    "\n",
    "    def fit(self, metric, type='agglomerative', dists_path='date_distances', k=10, max_iter=10_000):\n",
    "        with open(DATASETS_PATH + dists_path + '.pkl', 'rb') as f:\n",
    "            self.dists = pickle.load(f)\n",
    "        dists = self.get_dists(self.dists)\n",
    "        self.metric = metric\n",
    "        if type == 'agglomerative':\n",
    "            return self.run(dists, k)\n",
    "        else:\n",
    "            return self.run_k_means(dists, k, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T02:12:12.898662978Z",
     "start_time": "2023-05-31T02:12:12.892219438Z"
    }
   },
   "outputs": [],
   "source": [
    "c = Clustering()\n",
    "# clusters_euc = c.fit(metric=Metric('max_dist'), type='k_means', k=10_000, max_iter=10_000)\n",
    "#\n",
    "# with open(CLUSTERS_PATH + 'k_means_max_dist.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_euc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n",
      "Starting counting distances between clusters...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/26730 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a79d19928cf242ecb916caab617953e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clusters_euc = c.fit(metric=Metric('min_dist'), type='aglomerative', k=100_000)\n",
    "\n",
    "\n",
    "with open(CLUSTERS_PATH + 'ward_max_dist.pkl','wb') as f:\n",
    "     pickle.dump(clusters_euc, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-31T02:12:12.892397742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "c.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'k_means_euclidean.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_euc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
