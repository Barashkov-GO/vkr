{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:30.325753694Z",
     "start_time": "2023-05-31T00:47:30.320183217Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "DICTS_PATH = 'out/dicts/'\n",
    "CLUSTERS_PATH = 'out/clusters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.332835688Z",
     "start_time": "2023-05-31T00:47:30.320308783Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocesspandas import applyparallel\n",
    "from pandarallel import pandarallel\n",
    "import psutil\n",
    "from sys import getsizeof\n",
    "import networkx as nx\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "from netgraph import Graph, InteractiveGraph, EditableGraph\n",
    "\n",
    "import pickle\n",
    "import gc \n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.347144713Z",
     "start_time": "2023-05-31T00:47:31.334028148Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(DATASETS_PATH + 'date_distances.pkl', 'rb') as f:\n",
    "#     dists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.347335121Z",
     "start_time": "2023-05-31T00:47:31.337783715Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(DATASETS_PATH + 'user_purchases.pkl', 'rb') as f:\n",
    "#     dists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.347402598Z",
     "start_time": "2023-05-31T00:47:31.342942377Z"
    }
   },
   "outputs": [],
   "source": [
    "# dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391009542Z",
     "start_time": "2023-05-31T00:47:31.346132371Z"
    }
   },
   "outputs": [],
   "source": [
    "# dict(sorted(list(dists.items()), key=(lambda x: x[1][1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391349931Z",
     "start_time": "2023-05-31T00:47:31.388233346Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(dists.items()).sort(key=(lambda x: x[1][0]))\n",
    "# (product_1, product_2) - [mean data distance, count, quartile range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391476760Z",
     "start_time": "2023-05-31T00:47:31.388354393Z"
    }
   },
   "outputs": [],
   "source": [
    "def default(mean, count, scatter):\n",
    "    return (mean + abs(scatter)) / (count ** 2)\n",
    "\n",
    "def get_dists(dists, count_lower=10, dist_func=default):\n",
    "    return dict([(i[0], dist_func(i[1][0], i[1][1], i[1][2])) \n",
    "                 for i in dists.items() \n",
    "                 if (i[1][1] >= count_lower\n",
    "                     or dist_func(i[1][0], i[1][1], i[1][2]) != 0) \n",
    "                 and dist_func(i[1][0], i[1][1], i[1][2]) >= 0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391589021Z",
     "start_time": "2023-05-31T00:47:31.388407433Z"
    }
   },
   "outputs": [],
   "source": [
    "# dists = get_dists(dists, count_lower=30, dist_func=default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391698747Z",
     "start_time": "2023-05-31T00:47:31.388451365Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'dists.pkl', 'wb') as f:\n",
    "#     pickle.dump(dists, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.391899384Z",
     "start_time": "2023-05-31T00:47:31.388490259Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_means_clustering(dists, k, max_iterations=100):\n",
    "    \n",
    "    def dist_between_products(product1, product2):\n",
    "        if product1 == product2:\n",
    "            return 0\n",
    "\n",
    "        if (product1, product2) in dists:\n",
    "            return dists[(product1, product2)]\n",
    "\n",
    "        if (product2, product1) in dists:\n",
    "            return dists[(product2, product1)]\n",
    "\n",
    "        return float('inf')\n",
    "    \n",
    "    \n",
    "    def comp(product, mini):\n",
    "        return dist_between_products(product, mini)\n",
    "    \n",
    "    \n",
    "    def get_dist_between(product, cluster):\n",
    "        dist = 0.0\n",
    "        cnt = 0\n",
    "        for c in cluster:\n",
    "            if (product, c) in dists:\n",
    "                dist += dists[(product, c)]\n",
    "                cnt += 1\n",
    "            elif (c, product) in dists:\n",
    "                dist += dists[(c, product)]\n",
    "                cnt += 1\n",
    "        if cnt == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        return dist / cnt\n",
    "    \n",
    "    def clear_clusters(clusters):\n",
    "        for cluster in clusters:\n",
    "        \n",
    "            mini = (float('inf'), 0)\n",
    "            for i, p in enumerate(cluster):\n",
    "                mean_dist = get_dist_between(p, cluster)\n",
    "                if mean_dist < mini[0]:\n",
    "                    mini = (mean_dist, p)\n",
    "\n",
    "            cluster = sorted(cluster, key=(lambda x: comp(x, mini[1])), reverse=False)\n",
    "            cluster = [p for p in cluster if dist_between_products(p, mini[1]) < float('inf')]\n",
    "        \n",
    "        clusters = [i for i in clusters if len(i) > 0]\n",
    "        return clusters\n",
    "        \n",
    "        \n",
    "    products = np.unique(np.concatenate(list(dists.keys())))\n",
    "    \n",
    "    clusters = np.random.choice(products, k, replace=False)\n",
    "    clusters = [[c] for c in clusters]\n",
    "    products = products[~np.isin(products, clusters)]\n",
    "    \n",
    "    \n",
    "    mi_break = False\n",
    "    ri_break = False\n",
    "    \n",
    "    print('Starting products splitting to clusters...')\n",
    "    for p in tqdm(products):\n",
    "        p_dist = [get_dist_between(p, c) for c in clusters]\n",
    "        pos = np.argmin(p_dist)\n",
    "        clusters[pos].append(p)\n",
    "        products = products[products != p]\n",
    "            \n",
    "    \n",
    "    \n",
    "    print('Starting operating over clusters...')\n",
    "    for _ in range(max_iterations):\n",
    "        \n",
    "        clusters_prev = clusters\n",
    "        \n",
    "        for c in tqdm(clusters):\n",
    "            for p in c:\n",
    "                p_dist = [get_dist_between(p, c_other) for c_other in clusters]\n",
    "                pos = np.argmin(p_dist)\n",
    "                c.remove(p)\n",
    "                clusters[pos].append(p)\n",
    "                \n",
    "                \n",
    "        if clusters_prev == clusters:\n",
    "            print('Clusters stabilizied!')\n",
    "            ri_break = True\n",
    "            break\n",
    "            \n",
    "    if not ri_break:\n",
    "        print('Stopped for maximum of iterations: {}'.format(max_iterations))\n",
    "    \n",
    "    clusters = clear_clusters(clusters)\n",
    "\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.392052531Z",
     "start_time": "2023-05-31T00:47:31.388597821Z"
    }
   },
   "outputs": [],
   "source": [
    "# clusters = k_means_clustering(dists, k=100, max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.441177583Z",
     "start_time": "2023-05-31T00:47:31.388642174Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'k_means.pkl','wb') as f:\n",
    "#      pickle.dump(clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.441393669Z",
     "start_time": "2023-05-31T00:47:31.432194886Z"
    }
   },
   "outputs": [],
   "source": [
    "# clusters_ward = ward_clustering(dists, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.441468881Z",
     "start_time": "2023-05-31T00:47:31.432300274Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'ward.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_ward, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.441533061Z",
     "start_time": "2023-05-31T00:47:31.432342513Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, method='euclidean', max=100):\n",
    "        self.method = method\n",
    "        self.max = max\n",
    "\n",
    "    def run(self, cluster1, cluster2, dists):\n",
    "        self.cluster1 = cluster1\n",
    "        self.cluster2 = cluster2\n",
    "        self.dists = dists\n",
    "\n",
    "        if self.method == 'euclidean':\n",
    "            return self.euclidean()\n",
    "        if self.method == 'min_dist':\n",
    "            return self.min_dist()\n",
    "        if self.method == 'max_dist':\n",
    "            return self.max_dist()\n",
    "        if self.method == 'average':\n",
    "            return self.average()\n",
    "        if self.method == 'ward':\n",
    "            return self.ward()\n",
    "\n",
    "    def _get(self, i, j):\n",
    "        if i == j:\n",
    "            return 0.0\n",
    "        if (i, j) in self.dists:\n",
    "            return self.dists[(i, j)]\n",
    "        if (j, i) in self.dists:\n",
    "            return self.dists[(j, i)]\n",
    "        return self.max\n",
    "\n",
    "\n",
    "    def euclidean(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j) ** 2\n",
    "        return s / (n1 + n2)\n",
    "\n",
    "\n",
    "    def min_dist(self):\n",
    "        s, mini = 0.0, self.max + 1\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s < mini:\n",
    "                    mini = s\n",
    "        return mini\n",
    "\n",
    "\n",
    "    def max_dist(self):\n",
    "        s, maxi = 0.0, -1.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s > maxi:\n",
    "                    maxi = s\n",
    "        return maxi\n",
    "\n",
    "\n",
    "    def average(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j)\n",
    "        return s / (n1 * n2)\n",
    "\n",
    "\n",
    "    def ward(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s_u, s_1, s_2 = 0.0, 0.0, 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s_u += self._get(i, j) ** 2\n",
    "\n",
    "        for i in range(n1):\n",
    "            for j in range(i + 1, n1):\n",
    "                s_1 += self._get(self.cluster1[i], self.cluster1[j])\n",
    "\n",
    "        for i in range(n2):\n",
    "            for j in range(i + 1, n2):\n",
    "                s_2 += self._get(self.cluster2[i], self.cluster2[j])\n",
    "        return (s_u - s_1 - s_2) / (n1 + n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.441595458Z",
     "start_time": "2023-05-31T00:47:31.432398588Z"
    }
   },
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, get_dists=get_dists):\n",
    "        self.get_dists = get_dists\n",
    "        self.statistics = {\n",
    "            'min_distances': [],\n",
    "            'time_of_iter': [],\n",
    "            'time_of_all': 0.0,\n",
    "            'count_of_iters': 0.0,\n",
    "            }\n",
    "\n",
    "    def get_stats(self):\n",
    "        self.statistics['time_of_iter'] = np.array(self.statistics['time_of_iter']).mean()\n",
    "        for k in self.statistics.keys():\n",
    "            print(f\"{k} --- {self.statistics[k]}\")\n",
    "        return self.statistics\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_clusters(cluster1, cluster2):\n",
    "        merged_cluster = cluster1 + cluster2\n",
    "        return merged_cluster\n",
    "\n",
    "    def run(self, dists, k):\n",
    "        start0 = datetime.now()\n",
    "\n",
    "        elements = np.unique(list(dists.keys())[:100_000])\n",
    "        # elements = list(set(list(np.concatenate(dists.keys())[:10_000])))\n",
    "        clusters = [[i] for i in elements]\n",
    "        iters = len(elements) - k\n",
    "\n",
    "        clusters_dists = {}\n",
    "\n",
    "        for _ in tqdm(range(iters)):\n",
    "            start = datetime.now()\n",
    "            min_distance = np.inf\n",
    "            merge_indices = (0, 0)\n",
    "\n",
    "            for i in range(len(clusters)):\n",
    "                for j in range(i + 1, len(clusters)):\n",
    "                    distance = self.metric.run(clusters[i], clusters[j], dists)\n",
    "                    # clusters_dists[i, j] = distance\n",
    "\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        merge_indices = (i, j)\n",
    "\n",
    "            i, j = merge_indices\n",
    "            merged_cluster = self._merge_clusters(clusters[i], clusters[j])\n",
    "\n",
    "            del clusters[j]\n",
    "            del clusters[i]\n",
    "\n",
    "            clusters.append(merged_cluster)\n",
    "\n",
    "            self.statistics['min_distances'].append(min_distance)\n",
    "            self.statistics['time_of_iter'].append(datetime.now() - start)\n",
    "        self.statistics['count_of_iters'] = iters\n",
    "        self.statistics['time_of_all'] = datetime.now() - start0\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def run_k_means(self, dists, k, max_iter=10_000):\n",
    "        # Можно наканпливать minimal_dist, как внутрикластерное расстояние (в агломеративных тоже)\n",
    "        # Можно сохранять среднее расстояние между кластерами и внутри кластеров, чтобы показывать на графике\n",
    "\n",
    "        start0 = datetime.now()\n",
    "        elements = np.unique(sorted(list(dists.keys()))[:25_000])\n",
    "\n",
    "        clusters = np.random.choice(elements, k, replace=False)\n",
    "        elements = elements[~np.isin(elements, clusters)]\n",
    "        clusters = [[c] for c in clusters]\n",
    "\n",
    "\n",
    "        print('Starting elements splitting by clusters...')\n",
    "        for e in tqdm(elements):\n",
    "            minimal_dist = self.metric.max * 5.0\n",
    "            cluster_index = 0\n",
    "            for i, c in enumerate(clusters):\n",
    "                dist = self.metric.run([e], c, dists)\n",
    "                if dist < minimal_dist:\n",
    "                    minimal_dist = dist\n",
    "                    cluster_index = i\n",
    "\n",
    "            clusters[cluster_index].append(e)\n",
    "\n",
    "\n",
    "        print('Starting operating over clusters...')\n",
    "        for _ in tqdm(range(max_iter)):\n",
    "            self.statistics['count_of_iters'] += 1\n",
    "            start = datetime.now()\n",
    "            prev_clusters = clusters.copy()\n",
    "            for c1 in clusters:\n",
    "                for pos_el, el in enumerate(c1):\n",
    "                    minimal_dist = self.metric.max * 5.0\n",
    "                    cluster_index = 0\n",
    "                    for i, c in enumerate(clusters):\n",
    "                        dist = self.metric.run([el], c, dists)\n",
    "                        if dist < minimal_dist:\n",
    "                            minimal_dist = dist\n",
    "                            cluster_index = i\n",
    "\n",
    "                    self.statistics['min_distances'].append(minimal_dist)\n",
    "\n",
    "                    del c1[pos_el]\n",
    "                    clusters[cluster_index].append(el)\n",
    "\n",
    "            if prev_clusters == clusters:\n",
    "                print('Clusters stabilizied!')\n",
    "                self.statistics['time_of_all'] = datetime.now() - start0\n",
    "                return clusters\n",
    "\n",
    "            self.statistics['time_of_iter'].append(datetime.now() - start)\n",
    "\n",
    "        print('Stopped for maximum iterations: {}'.format(max_iter))\n",
    "        self.statistics['time_of_all'] = datetime.now() - start0\n",
    "        return clusters\n",
    "\n",
    "\n",
    "    def fit(self, metric, type='aglomerative', dists_path='date_distances', k=10, max_iter=10_000):\n",
    "        with open(DATASETS_PATH + dists_path + '.pkl', 'rb') as f:\n",
    "            self.dists = pickle.load(f)\n",
    "\n",
    "        print('clustering...')\n",
    "\n",
    "        dists = self.get_dists(self.dists)\n",
    "\n",
    "        self.metric = metric\n",
    "\n",
    "        if type == 'aglomerative':\n",
    "            return self.run(dists, k)\n",
    "        else:\n",
    "            return self.run_k_means(dists, k, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T00:47:31.500721882Z",
     "start_time": "2023-05-31T00:47:31.436168552Z"
    }
   },
   "outputs": [],
   "source": [
    "c = Clustering()\n",
    "# clusters_euc = c.fit(metric=Metric('max_dist'), type='k_means', k=10_000, max_iter=10_000)\n",
    "#\n",
    "# with open(CLUSTERS_PATH + 'k_means_max_dist.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_euc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2201 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa901bcf0530467ab24bb3dfd1c3360b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m clusters_euc \u001B[38;5;241m=\u001B[39m \u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMetric\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_dist\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maglomerative\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10_000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10_000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(CLUSTERS_PATH \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mward_max_dist.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      5\u001B[0m      pickle\u001B[38;5;241m.\u001B[39mdump(clusters_euc, f)\n",
      "Cell \u001B[0;32mIn[17], line 126\u001B[0m, in \u001B[0;36mClustering.fit\u001B[0;34m(self, metric, type, dists_path, k, max_iter)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric \u001B[38;5;241m=\u001B[39m metric\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maglomerative\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_k_means(dists, k, max_iter)\n",
      "Cell \u001B[0;32mIn[17], line 37\u001B[0m, in \u001B[0;36mClustering.run\u001B[0;34m(self, dists, k)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(clusters)):\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(clusters)):\n\u001B[0;32m---> 37\u001B[0m         distance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclusters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclusters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdists\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m distance \u001B[38;5;241m<\u001B[39m min_distance:\n\u001B[1;32m     40\u001B[0m             min_distance \u001B[38;5;241m=\u001B[39m distance\n",
      "Cell \u001B[0;32mIn[16], line 16\u001B[0m, in \u001B[0;36mMetric.run\u001B[0;34m(self, cluster1, cluster2, dists)\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_dist()\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_dist\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_dist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maverage()\n",
      "Cell \u001B[0;32mIn[16], line 56\u001B[0m, in \u001B[0;36mMetric.max_dist\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcluster1:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcluster2:\n\u001B[0;32m---> 56\u001B[0m         s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m s \u001B[38;5;241m>\u001B[39m maxi:\n\u001B[1;32m     59\u001B[0m             maxi \u001B[38;5;241m=\u001B[39m s\n",
      "Cell \u001B[0;32mIn[16], line 25\u001B[0m, in \u001B[0;36mMetric._get\u001B[0;34m(self, i, j)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m j:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (i, j) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdists:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdists[(i, j)]\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (j, i) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdists:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clusters_euc = c.fit(metric=Metric('max_dist'), type='aglomerative', k=10_000, max_iter=10_000)\n",
    "\n",
    "\n",
    "with open(CLUSTERS_PATH + 'ward_max_dist.pkl','wb') as f:\n",
    "     pickle.dump(clusters_euc, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-31T00:49:18.669404122Z",
     "start_time": "2023-05-31T00:47:31.480222275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-31T00:49:18.665239807Z"
    }
   },
   "outputs": [],
   "source": [
    "c.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-31T00:49:18.667078893Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'k_means_euclidean.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_euc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
