{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:44.283899066Z",
     "start_time": "2023-05-30T13:49:44.276832871Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "DICTS_PATH = 'out/dicts/'\n",
    "CLUSTERS_PATH = 'out/clusters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.323121649Z",
     "start_time": "2023-05-30T13:49:44.278963190Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocesspandas import applyparallel\n",
    "from pandarallel import pandarallel\n",
    "import psutil\n",
    "from sys import getsizeof\n",
    "import networkx as nx\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "from netgraph import Graph, InteractiveGraph, EditableGraph\n",
    "\n",
    "import pickle\n",
    "import gc \n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.358048517Z",
     "start_time": "2023-05-30T13:49:47.323573031Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(DATASETS_PATH + 'date_distances.pkl', 'rb') as f:\n",
    "#     dists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.379337518Z",
     "start_time": "2023-05-30T13:49:47.326281744Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(DATASETS_PATH + 'user_purchases.pkl', 'rb') as f:\n",
    "#     dists = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.421214130Z",
     "start_time": "2023-05-30T13:49:47.326796648Z"
    }
   },
   "outputs": [],
   "source": [
    "# dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.509507636Z",
     "start_time": "2023-05-30T13:49:47.327247990Z"
    }
   },
   "outputs": [],
   "source": [
    "# dict(sorted(list(dists.items()), key=(lambda x: x[1][1]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.936210684Z",
     "start_time": "2023-05-30T13:49:47.358471124Z"
    }
   },
   "outputs": [],
   "source": [
    "# list(dists.items()).sort(key=(lambda x: x[1][0]))\n",
    "# (product_1, product_2) - [mean data distance, count, quartile range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:47.987487941Z",
     "start_time": "2023-05-30T13:49:47.359240614Z"
    }
   },
   "outputs": [],
   "source": [
    "def default(mean, count, scatter):\n",
    "    return (mean + abs(scatter)) / (count ** 2)\n",
    "\n",
    "def get_dists(dists, count_lower=10, dist_func=default):\n",
    "    return dict([(i[0], dist_func(i[1][0], i[1][1], i[1][2])) \n",
    "                 for i in dists.items() \n",
    "                 if (i[1][1] >= count_lower\n",
    "                     or dist_func(i[1][0], i[1][1], i[1][2]) != 0) \n",
    "                 and dist_func(i[1][0], i[1][1], i[1][2]) >= 0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.037628528Z",
     "start_time": "2023-05-30T13:49:47.359692667Z"
    }
   },
   "outputs": [],
   "source": [
    "# dists = get_dists(dists, count_lower=30, dist_func=default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.094057157Z",
     "start_time": "2023-05-30T13:49:47.361841812Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'dists.pkl', 'wb') as f:\n",
    "#     pickle.dump(dists, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.129911348Z",
     "start_time": "2023-05-30T13:49:47.362247737Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_means_clustering(dists, k, max_iterations=100):\n",
    "    \n",
    "    def dist_between_products(product1, product2):\n",
    "        if product1 == product2:\n",
    "            return 0\n",
    "\n",
    "        if (product1, product2) in dists:\n",
    "            return dists[(product1, product2)]\n",
    "\n",
    "        if (product2, product1) in dists:\n",
    "            return dists[(product2, product1)]\n",
    "\n",
    "        return float('inf')\n",
    "    \n",
    "    \n",
    "    def comp(product, mini):\n",
    "        return dist_between_products(product, mini)\n",
    "    \n",
    "    \n",
    "    def get_dist_between(product, cluster):\n",
    "        dist = 0.0\n",
    "        cnt = 0\n",
    "        for c in cluster:\n",
    "            if (product, c) in dists:\n",
    "                dist += dists[(product, c)]\n",
    "                cnt += 1\n",
    "            elif (c, product) in dists:\n",
    "                dist += dists[(c, product)]\n",
    "                cnt += 1\n",
    "        if cnt == 0:\n",
    "            return float('inf')\n",
    "        \n",
    "        return dist / cnt\n",
    "    \n",
    "    def clear_clusters(clusters):\n",
    "        for cluster in clusters:\n",
    "        \n",
    "            mini = (float('inf'), 0)\n",
    "            for i, p in enumerate(cluster):\n",
    "                mean_dist = get_dist_between(p, cluster)\n",
    "                if mean_dist < mini[0]:\n",
    "                    mini = (mean_dist, p)\n",
    "\n",
    "            cluster = sorted(cluster, key=(lambda x: comp(x, mini[1])), reverse=False)\n",
    "            cluster = [p for p in cluster if dist_between_products(p, mini[1]) < float('inf')]\n",
    "        \n",
    "        clusters = [i for i in clusters if len(i) > 0]\n",
    "        return clusters\n",
    "        \n",
    "        \n",
    "    products = np.unique(np.concatenate(list(dists.keys())))\n",
    "    \n",
    "    clusters = np.random.choice(products, k, replace=False)\n",
    "    clusters = [[c] for c in clusters]\n",
    "    products = products[~np.isin(products, clusters)]\n",
    "    \n",
    "    \n",
    "    mi_break = False\n",
    "    ri_break = False\n",
    "    \n",
    "    print('Starting products splitting to clusters...')\n",
    "    for p in tqdm(products):\n",
    "        p_dist = [get_dist_between(p, c) for c in clusters]\n",
    "        pos = np.argmin(p_dist)\n",
    "        clusters[pos].append(p)\n",
    "        products = products[products != p]\n",
    "            \n",
    "    \n",
    "    \n",
    "    print('Starting operating over clusters...')\n",
    "    for _ in range(max_iterations):\n",
    "        \n",
    "        clusters_prev = clusters\n",
    "        \n",
    "        for c in tqdm(clusters):\n",
    "            for p in c:\n",
    "                p_dist = [get_dist_between(p, c_other) for c_other in clusters]\n",
    "                pos = np.argmin(p_dist)\n",
    "                c.remove(p)\n",
    "                clusters[pos].append(p)\n",
    "                \n",
    "                \n",
    "        if clusters_prev == clusters:\n",
    "            print('Clusters stabilizied!')\n",
    "            ri_break = True\n",
    "            break\n",
    "            \n",
    "    if not ri_break:\n",
    "        print('Stopped for maximum of iterations: {}'.format(max_iterations))\n",
    "    \n",
    "    clusters = clear_clusters(clusters)\n",
    "\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.131512546Z",
     "start_time": "2023-05-30T13:49:47.362665215Z"
    }
   },
   "outputs": [],
   "source": [
    "# clusters = k_means_clustering(dists, k=100, max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.132378821Z",
     "start_time": "2023-05-30T13:49:47.379696724Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'k_means.pkl','wb') as f:\n",
    "#      pickle.dump(clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.132863667Z",
     "start_time": "2023-05-30T13:49:47.382485200Z"
    }
   },
   "outputs": [],
   "source": [
    "# clusters_ward = ward_clustering(dists, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.148923010Z",
     "start_time": "2023-05-30T13:49:47.385186179Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(CLUSTERS_PATH + 'ward.pkl','wb') as f:\n",
    "#      pickle.dump(clusters_ward, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.184119806Z",
     "start_time": "2023-05-30T13:49:47.385706212Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, cluster1, cluster2, dists, max=100):\n",
    "        self.cluster1 = cluster1\n",
    "        self.cluster2 = cluster2\n",
    "        self.dists = dists\n",
    "        self.max = max\n",
    "\n",
    "\n",
    "    def _get(self, i, j):\n",
    "        if i == j:\n",
    "            return 0.0\n",
    "        if (i, j) in self.dists:\n",
    "            return self.dists[(i, j)]\n",
    "        if (j, i) in self.dists:\n",
    "            return self.dists[(j, i)]\n",
    "        return self.max\n",
    "\n",
    "\n",
    "    def euclidean(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j) ** 2\n",
    "        return s / (n1 + n2)\n",
    "\n",
    "\n",
    "    def min_dist(self):\n",
    "        s, mini = 0.0, self.max + 1\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s < mini:\n",
    "                    mini = s\n",
    "        return mini\n",
    "\n",
    "\n",
    "    def max_dist(self):\n",
    "        s, maxi = 0.0, -1.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s = self._get(i, j)\n",
    "\n",
    "                if s > maxi:\n",
    "                    maxi = s\n",
    "        return maxi\n",
    "\n",
    "\n",
    "    def average(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s = 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s += self._get(i, j)\n",
    "        return s / (n1 * n2)\n",
    "\n",
    "\n",
    "    def ward(self):\n",
    "        n1, n2 = len(self.cluster1), len(self.cluster2)\n",
    "        s_u, s_1, s_2 = 0.0, 0.0, 0.0\n",
    "        for i in self.cluster1:\n",
    "            for j in self.cluster2:\n",
    "                s_u += self._get(i, j) ** 2\n",
    "\n",
    "        for i in range(n1):\n",
    "            for j in range(i + 1, n1):\n",
    "                s_1 += self._get(self.cluster1[i], self.cluster1[j])\n",
    "\n",
    "        for i in range(n2):\n",
    "            for j in range(i + 1, n2):\n",
    "                s_2 += self._get(self.cluster2[i], self.cluster2[j])\n",
    "        return (s_u - s_1 - s_2) / (n1 + n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T13:49:48.226234866Z",
     "start_time": "2023-05-30T13:49:47.386140251Z"
    }
   },
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, get_dists=get_dists):\n",
    "        self.get_dists = get_dists\n",
    "        self.statistics = {\n",
    "            'min_distances': [],\n",
    "            'time_of_iter': [],\n",
    "            'time_of_all': 0.0,\n",
    "            'count_of_iters': 0.0,\n",
    "            }\n",
    "\n",
    "    def get_stats(self):\n",
    "        self.statistics['time_of_iter'] = np.array(self.statistics['time_of_iter']).mean()\n",
    "        for k in self.statistics.keys():\n",
    "            print(f\"{k} --- {self.statistics[k]}\")\n",
    "        return self.statistics\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_clusters(cluster1, cluster2):\n",
    "        merged_cluster = cluster1 + cluster2\n",
    "        return merged_cluster\n",
    "\n",
    "    def run(self, dists, k):\n",
    "        start0 = datetime.now()\n",
    "\n",
    "        elements = np.unique(list(dists.keys())[:100_000])\n",
    "        # elements = list(set(list(np.concatenate(dists.keys())[:10_000])))\n",
    "        clusters = [[i] for i in elements]\n",
    "        iters = len(elements) - k\n",
    "\n",
    "        for _ in tqdm(range(iters)):\n",
    "            start = datetime.now()\n",
    "            min_distance = np.inf\n",
    "            merge_indices = (0, 0)\n",
    "\n",
    "            for i in range(len(clusters)):\n",
    "                for j in range(i + 1, len(clusters)):\n",
    "                    cluster1 = clusters[i]\n",
    "                    cluster2 = clusters[j]\n",
    "                    distance = self.metric(cluster1, cluster2, dists)\n",
    "\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        merge_indices = (i, j)\n",
    "\n",
    "            i, j = merge_indices\n",
    "            merged_cluster = self._merge_clusters(clusters[i], clusters[j])\n",
    "\n",
    "            del clusters[j]\n",
    "            del clusters[i]\n",
    "\n",
    "            clusters.append(merged_cluster)\n",
    "\n",
    "            self.statistics['min_distances'].append(min_distance)\n",
    "            self.statistics['time_of_iter'].append(datetime.now() - start)\n",
    "        self.statistics['count_of_iters'] = iters\n",
    "        self.statistics['time_of_all'] = datetime.now() - start0\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def fit(self, metric, dists_path='date_distances', k=10):\n",
    "        with open(DATASETS_PATH + dists_path + '.pkl', 'rb') as f:\n",
    "            self.dists = pickle.load(f)\n",
    "\n",
    "        dists = self.get_dists(self.dists)\n",
    "\n",
    "        self.metric = metric\n",
    "        return self.run(dists, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-30T13:49:47.386674211Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric(cluster1, cluster2, dists, max=100):\n",
    "    return Metric(cluster1, cluster2, dists, max).euclidean()\n",
    "\n",
    "c = Clustering()\n",
    "clusters_euc = c.fit(metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "c.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
