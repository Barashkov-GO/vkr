{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "CLUSTERS_PATH = 'out/clusters/'\n",
    "DICTS_PATH = 'out/dicts/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import timedelta\n",
    "from helper import save\n",
    "\n",
    "import psutil\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from distances import Distances\n",
    "from clustering import Clustering, get_dists\n",
    "from visualisation import Visualisation\n",
    "\n",
    "from netgraph import Graph, InteractiveGraph, EditableGraph\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "tqdm.pandas()\n",
    "from helper import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "\n",
    "    def dist_between(self, cluster1, cluster2, dists):\n",
    "        s = 0.0\n",
    "        cnt = 0\n",
    "        for i in cluster1:\n",
    "            for j in cluster2:\n",
    "                s += self.get_dist(i, j, dists) ** 2\n",
    "                cnt += 1\n",
    "\n",
    "        if s == 0:\n",
    "            return 0.01\n",
    "        return np.sqrt(s) / cnt\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def tp_tn_fp_fn(clusters1, clusters2):\n",
    "        elements = list(set(np.concatenate(clusters1)))\n",
    "        cnt = 0\n",
    "        tp, tn = 0, 0\n",
    "        fn, fp = 0, 0\n",
    "        for i in range(len(elements)):\n",
    "            for j in range(i + 1, len(elements)):\n",
    "\n",
    "                in_one1 = False\n",
    "                in_one2 = False\n",
    "\n",
    "                for c1 in clusters1:\n",
    "                    if elements[i] in c1 and elements[j] in c1:\n",
    "                        in_one1 = True\n",
    "                        break\n",
    "\n",
    "                for c2 in clusters2:\n",
    "                    if elements[i] in c2 and elements[j] in c2:\n",
    "                        in_one2 = True\n",
    "                        break\n",
    "\n",
    "                if in_one1 and in_one2:\n",
    "                    tp += 1\n",
    "\n",
    "                elif (not in_one1) and (not in_one2):\n",
    "                    tn += 1\n",
    "\n",
    "                elif in_one1 and (not in_one2):\n",
    "                    fn += 1\n",
    "\n",
    "                elif (not in_one1) and in_one2:\n",
    "                    fp += 1\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "        return tp, tn, fp, fn\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dist(i, j, dists):\n",
    "        if (i, j) in dists:\n",
    "            return dists[i, j]\n",
    "\n",
    "        if (j, i) in dists:\n",
    "            return dists[j, i]\n",
    "\n",
    "        return 100\n",
    "\n",
    "    @staticmethod\n",
    "    def rand(tp, tn, fp, fn):\n",
    "        cnt = tp + tn + fp + fn\n",
    "        return (tp + tn) / cnt\n",
    "\n",
    "    @staticmethod\n",
    "    def adjusted_rand(tp, tn, fp, fn):\n",
    "        n = tp + tn + fp + fn\n",
    "        return (tp + tn) / n - ((tp + fp) * (tp + fn) + (fn + tn) * (fp + tn)) / (n ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def fm(tp, tn, fp, fn):\n",
    "        return tp / np.sqrt((tp + fp) * (tp + fn))\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard(tp, tn, fp, fn):\n",
    "        return tp / (tp + fp + fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def f1(tp, tn, fp, fn):\n",
    "        p, r = tp / (tp + fp), tp / (tp + fn)\n",
    "        return 2 * p * r / (p + r)\n",
    "\n",
    "    @staticmethod\n",
    "    def cohen(inter, outer):\n",
    "        mu = np.mean(inter)\n",
    "        d = np.mean(outer)\n",
    "        return (mu - d) / (max(mu, d))\n",
    "\n",
    "\n",
    "    def silhouette(self, clusters, dists):\n",
    "        s = dict()\n",
    "        for i1 in range(len(clusters)):\n",
    "            closest_cluster = i1\n",
    "            min_d = np.inf\n",
    "\n",
    "            for i2 in range(len(clusters)):\n",
    "                if i2 == i1:\n",
    "                    continue\n",
    "                d = self.dist_between(clusters[i1], clusters[i2], dists)\n",
    "                if d < min_d:\n",
    "                    min_d = d\n",
    "                    closest_cluster = i2\n",
    "\n",
    "\n",
    "            for j in range(len(clusters[i1])):\n",
    "                sum = 0.0\n",
    "                cnt = 0.0\n",
    "                for j1 in range(len(clusters[i1])):\n",
    "                    if j != j1:\n",
    "                        sum += self.get_dist(clusters[i1][j], clusters[i1][j1], dists)\n",
    "                        cnt += 1\n",
    "\n",
    "                aj = sum / cnt\n",
    "                sum = 0.0\n",
    "                cnt = 0.0\n",
    "                for j1 in range(len(clusters[closest_cluster])):\n",
    "                    sum += self.get_dist(clusters[i1][j], clusters[closest_cluster][j1], dists)\n",
    "                    cnt += 1\n",
    "\n",
    "                bj = sum / cnt\n",
    "\n",
    "                s[clusters[i1][j]] = (bj - aj) / max(bj, aj)\n",
    "\n",
    "        return s\n",
    "\n",
    "    def inter(self, clusters, dists):\n",
    "        res = []\n",
    "        for cluster in clusters:\n",
    "            s = 0.0\n",
    "            cnt = 0\n",
    "            for i in range(len(cluster)):\n",
    "                for j in range(i + 1, len(cluster)):\n",
    "                    s += self.get_dist(i, j, dists) ** 2\n",
    "                    cnt += 1\n",
    "            if cnt == 0:\n",
    "                res.append(s)\n",
    "            else:\n",
    "                res.append(np.sqrt(s) / cnt)\n",
    "        return res\n",
    "\n",
    "    def outer(self, clusters, dists):\n",
    "        outer = np.full((len(clusters), len(clusters)), 0)\n",
    "        for i in range(len(clusters)):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                outer[i, j] = self.dist_between(clusters[i], clusters[j], dists)\n",
    "                outer[j, i] = outer[i, j]\n",
    "\n",
    "        return outer\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def dbi(inter, outer):\n",
    "        s = 0.0\n",
    "        for i in range(len(inter)):\n",
    "            max = -np.inf\n",
    "            for j in range(len(inter)):\n",
    "                if i != j:\n",
    "                    dbi = (inter[i] + inter[j]) / outer[i, j]\n",
    "                    if dbi > max:\n",
    "                        max = dbi\n",
    "            s += max\n",
    "        return s / len(inter)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def plot(stats):\n",
    "        names = list(stats.keys())\n",
    "        renaming = {\n",
    "            'silhouette': 'Silhouette Index',\n",
    "            'dbi': 'Daviesâ€“Bouldin Index',\n",
    "            'cohen': 'Cohen\\'s Index',\n",
    "            'jaccard': 'Jaccard Coefficient',\n",
    "            'fm': 'Fowlkes-Mallows Index',\n",
    "            'rand': 'Rand Index',\n",
    "            'adjusted_rand': 'Adjusted Rand Index',\n",
    "            'wss': 'Cluster Cohesion',\n",
    "            'bss': 'Cluster Separation',\n",
    "            'f1': 'F1-score'\n",
    "        }\n",
    "        optimal = {\n",
    "            'silhouette': 1,\n",
    "            'dbi': 0,\n",
    "            'cohen': 1,\n",
    "            'jaccard': 1,\n",
    "            'fm': 1,\n",
    "            'rand': 1,\n",
    "            'adjusted_rand': 1,\n",
    "            'wss': 0,\n",
    "            'bss': 100,\n",
    "            'f1': 1\n",
    "        }\n",
    "\n",
    "        for metric in ['silhouette', 'jaccard', 'fm', 'rand', 'adjusted_rand', 'f1']:\n",
    "            values = []\n",
    "            for n in names:\n",
    "                # if metric == 'silhouette':\n",
    "                #     values.append(np.mean(list(stats[n][metric].values())))\n",
    "                # else:\n",
    "                values.append(stats[n][metric])\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.grid(zorder=0)\n",
    "            plt.title(label=renaming[metric])\n",
    "            plt.bar(names, values)\n",
    "            plt.axhline(optimal[metric], color='red', label='optimal', linestyle='--')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.xlabel('Method')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend()\n",
    "            plt.savefig(FIGURES_PATH + '___' + metric)\n",
    "\n",
    "        for metric in ['dbi', 'cohen', 'wss', 'bss']:\n",
    "            values1, values2 = [], []\n",
    "            for n in names:\n",
    "                values1.append(stats[n][metric][0])\n",
    "                values2.append(stats[n][metric][1])\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.grid(zorder=0)\n",
    "            plt.title(label=renaming[metric])\n",
    "\n",
    "            names_axis = np.arange(len(names))\n",
    "            plt.bar(names_axis - 0.2, values1, 0.4, label='First clustering')\n",
    "            plt.bar(names_axis + 0.2, values2, 0.4, label='Second clustering')\n",
    "            plt.xticks(names_axis, names, rotation=45)\n",
    "            # plt.bar(names, values)\n",
    "            plt.axhline(optimal[metric], color='red', label='optimal', linestyle='--')\n",
    "            plt.xlabel('Method')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend()\n",
    "            plt.savefig(FIGURES_PATH + '___' + metric)\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(label='Minimal distances between clusters')\n",
    "        for n in names:\n",
    "            min_dists = stats[n]['statistics']['min_distances']\n",
    "            plt.plot(min_dists, label=n)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Minimal distance')\n",
    "        plt.savefig(FIGURES_PATH + '___' + 'min_dists')\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.title(label='Time of clustering')\n",
    "        times = []\n",
    "        for n in names:\n",
    "            times.append(stats[n]['statistics']['time_of_all'].seconds)\n",
    "        plt.grid(zorder=0)\n",
    "        plt.bar(names, times)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.xlabel('Method')\n",
    "        plt.ylabel('Time, seconds')\n",
    "        plt.legend()\n",
    "        plt.savefig(FIGURES_PATH + '___' + 'time_of_clustering')\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(label='Times of iterations')\n",
    "        for n in names:\n",
    "            times = stats[n]['statistics']['time_of_iter']\n",
    "            if len(times) != 0:\n",
    "                if type(times[0]) != int:\n",
    "                    for i in range(len(times)):\n",
    "                        times[i] = times[i].microseconds\n",
    "                plt.plot(times, label=n)\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Time, microseconds')\n",
    "        plt.savefig(FIGURES_PATH + '___' + 'times')\n",
    "\n",
    "    @staticmethod\n",
    "    def print_result(stats):\n",
    "        print('Optimal:')\n",
    "        print(f'\\tsilhouette: 1\\n\\tdbi: min\\n\\tcohen: 1\\n\\tjaccard: 1\\n\\tfm: max\\n\\trand: 1\\n\\tadjusted_rand: 1\\n\\twss: 0\\n\\tbss: max\\n\\tf1: 1')\n",
    "\n",
    "        for method in list(stats.keys()):\n",
    "            print(f'Method: {method}')\n",
    "            for metric in ['silhouette', 'dbi', 'cohen', 'jaccard', 'fm', 'rand', 'adjusted_rand']:#, 'wss', 'bss', 'f1']:\n",
    "                if metric == 'silhouette':\n",
    "                    print(f'\\t{metric}: {np.mean(list(stats[method][metric].values()))}')\n",
    "                else:\n",
    "                    print(f'\\t{metric}: {stats[method][metric]}')\n",
    "\n",
    "\n",
    "    def run_statistics(self,\n",
    "                       path: str = 'data_processed',\n",
    "                       nrows: int = 1_000_000,\n",
    "                       top_lim: int = 1_000,\n",
    "                       k: int = 100,\n",
    "                       methods: list[str] = None,\n",
    "                       field: str = 'product_id'\n",
    "                       ):\n",
    "\n",
    "        data = pd.read_csv(DATASETS_PATH + path + '.csv', nrows=2 * nrows).drop(columns=['Unnamed: 0'])\n",
    "        x_train, x_test = train_test_split(data, test_size=0.5)\n",
    "        d1 = Distances(data=x_train, nrows=nrows)\n",
    "        d2 = Distances(data=x_test, nrows=nrows)\n",
    "\n",
    "        print(f'Collecting data for first...')\n",
    "        pp1 = d1.get_pp(top_lim=top_lim, batch_size=100_000, field=field)\n",
    "        print(f'Collecting data for second...')\n",
    "        pp2 = d2.get_pp(top_lim=top_lim, batch_size=100_000, field=field)\n",
    "\n",
    "        stats = dict()\n",
    "        if methods is None:\n",
    "            methods = ['min_dist', 'max_dist', 'average', 'weighted', 'ward', 'k_means']\n",
    "\n",
    "        print(f'Starting agglomerative clustering with \\n\\tfile: {path},\\n\\tfield: {field},\\n\\tnrows: {nrows},\\n\\ttop_lim: {top_lim}')\n",
    "\n",
    "        for m in methods:\n",
    "            c = Clustering(get_dists=get_dists)\n",
    "            print(f'Clustering with method {m}')\n",
    "            clusters1, dists1 = c.fit(metric='euclidean', method=m, top_lim=top_lim, k=k, dists=pp1)\n",
    "            clusters2, dists2 = c.fit(metric='euclidean', method=m, top_lim=top_lim, k=k, dists=pp2)\n",
    "\n",
    "            stats[m] = dict()\n",
    "            i, o = self.inter(clusters1, dists1), self.outer(clusters1, dists1)\n",
    "            i2, o2 = self.inter(clusters2, dists2), self.outer(clusters2, dists2)\n",
    "\n",
    "            stats[m]['inter'], stats[m]['outer'] = [i, i2], [o, o2]\n",
    "            stats[m]['wss'] = [np.mean(i), np.mean(i2)]\n",
    "            stats[m]['bss'] = [np.mean(o), np.mean(o2)]\n",
    "            stats[m]['cohen'], stats[m]['dbi'] = [self.cohen(i, o), self.cohen(i2, o2)], [self.dbi(i, o), self.dbi(i2, o2)]\n",
    "            stats[m]['silhouette'] = [np.mean(list(self.silhouette(clusters1, dists1).values())), np.mean(list(self.silhouette(clusters2, dists2).values()))]\n",
    "\n",
    "            tp, tn, fp, fn = self.tp_tn_fp_fn(clusters1, clusters2)\n",
    "\n",
    "            stats[m]['TP'], stats[m]['TN'], stats[m]['FP'], stats[m]['FN'] = tp, tn, fp, fn\n",
    "            stats[m]['f1'] = self.f1(tp, tn, fp, fn)\n",
    "            stats[m]['rand'] = self.rand(tp, tn, fp, fn)\n",
    "\n",
    "            stats[m]['jaccard'], stats[m]['adjusted_rand'], stats[m]['fm'] = self.jaccard(tp, tn, fp, fn), self.adjusted_rand(tp, tn, fp, fn), self.fm(tp, tn, fp, fn)\n",
    "\n",
    "            stats[m]['statistics'] = c.get_stats()\n",
    "\n",
    "\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "t = Tester()\n",
    "stats = t.run_statistics(nrows=1_000_000, top_lim=1000, k=200)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for first...\n",
      "Top of dataset length: 325284\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d82591b48d8148f7bef4556b2f5cce3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for second...\n",
      "Top of dataset length: 325553\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b36334b05764a848d0588fd63b5c36e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agglomerative clustering with \n",
      "\tfile: data_processed,\n",
      "\tfield: product_id,\n",
      "\tnrows: 1000000,\n",
      "\ttop_lim: 1000\n",
      "Clustering with method min_dist\n",
      "Starting counting distances between clusters...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1075 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c432a63f445461cb8ecc6c24a0d7c89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collapsing closest clusters...\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3217b323cc1244319941904e786959a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = Tester()\n",
    "t.plot(stats)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t.print_result(stats)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
