{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.055957Z",
     "end_time": "2023-04-28T15:42:45.110795Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.064224Z",
     "end_time": "2023-04-28T15:42:45.111097Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.069621Z",
     "end_time": "2023-04-28T15:42:45.112053Z"
    }
   },
   "outputs": [],
   "source": [
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "DICTS_PATH = 'out/dicts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.069749Z",
     "end_time": "2023-04-28T15:42:45.176453Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/receipts_new.csv', nrows=5_000_000)\n",
    "# data = data.rename(columns = {'line_item_id': 'product_id'})\n",
    "# data\n",
    "# data.head(1000).to_csv('datasets/receipts_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.051366Z",
     "end_time": "2023-04-28T15:42:45.177530Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что совпадают некоторые строки по ключевому признаку - transaction_key, необходимо произвести схлопывание данных по одинаковым ключам с суммированием признаков line_quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение обработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.063345Z",
     "end_time": "2023-04-28T15:42:45.178339Z"
    }
   },
   "outputs": [],
   "source": [
    "def save(data, name):\n",
    "    print('SAVING dataset: {}\\n'.format(name.upper()))\n",
    "    data.info(memory_usage='deep')\n",
    "    data.to_csv(DATASETS_PATH + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Схлопывание одинаковых позиций в чеках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.068829Z",
     "end_time": "2023-04-28T15:42:45.179835Z"
    }
   },
   "outputs": [],
   "source": [
    "def collapse(data):\n",
    "    # print('Collapsing data')\n",
    "    grouped_series = data[['transaction_key', 'product_id', 'line_quantity']].groupby(\n",
    "        by=['transaction_key', 'product_id'])['line_quantity'].sum()\n",
    "\n",
    "    # data = data.groupby(by=['transaction_key', 'product_id']).first().reset_index()\n",
    "\n",
    "    data = data.join(grouped_series, how='left', on=['transaction_key', 'product_id'], lsuffix='_old')\n",
    "    data = data.drop(columns=['line_quantity_old'])\n",
    "    return data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.068933Z",
     "end_time": "2023-04-28T15:42:45.198595Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = collapse(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование transaction_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.074208Z",
     "end_time": "2023-04-28T15:42:45.200325Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(str):\n",
    "    return str.split('_')[3:4][0]\n",
    "\n",
    "\n",
    "def get_key(str):\n",
    "    splitted = str.split('_')\n",
    "    ans = ''\n",
    "    for i in range(3):\n",
    "        ans += splitted[i]\n",
    "    ans += splitted[-1]\n",
    "    return int(ans)\n",
    "\n",
    "\n",
    "def transform_transaction_key(data):\n",
    "    global trans_id\n",
    "    # print('Transforming dates')\n",
    "    dates = data['transaction_key'].apply(get_data)\n",
    "    dates = pd.to_datetime(dates)\n",
    "    data['datetime'] = dates\n",
    "\n",
    "    # print('Transforming keys')\n",
    "    keys = data['transaction_key']\n",
    "    keys = keys.drop_duplicates()\n",
    "    keys = keys.to_frame()\n",
    "\n",
    "    for ind, key in keys.iterrows():\n",
    "        keys.at[ind, 'key_id'] = trans_id.push(key['transaction_key'])\n",
    "\n",
    "    data = data.join(keys.set_index('transaction_key'), how='left', on='transaction_key')\n",
    "    data = data.drop(columns=['transaction_key'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.074307Z",
     "end_time": "2023-04-28T15:42:45.202004Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_transaction_key(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование gid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.079440Z",
     "end_time": "2023-04-28T15:42:45.219062Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_gid(data):\n",
    "    global gids_id\n",
    "    # print('Transforming gid')\n",
    "    gids = data['gid']\n",
    "    gids = gids.drop_duplicates()\n",
    "    gids = gids.to_frame()\n",
    "\n",
    "    for ind, gid in gids.iterrows():\n",
    "        gids.at[ind, 'gid_id'] = gids_id.push(gid['gid'])\n",
    "\n",
    "    data = data.join(gids.set_index('gid'), on='gid', how='left')\n",
    "    return data.drop(columns=['gid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.079535Z",
     "end_time": "2023-04-28T15:42:45.219405Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_gid(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование line_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.084530Z",
     "end_time": "2023-04-28T15:42:45.221211Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_line_type(data):\n",
    "    global lines_id\n",
    "    # print('Transforming line_type')\n",
    "    line_types = data['line_type']\n",
    "    line_types = line_types.drop_duplicates()\n",
    "    line_types = line_types.to_frame()\n",
    "\n",
    "    for ind, line_type in line_types.iterrows():\n",
    "        line_types.at[ind, 'line_type_id'] = lines_id.push(line_type['line_type'])\n",
    "\n",
    "    data = data.join(line_types.set_index('line_type'), on='line_type', how='left')\n",
    "    return data.drop(columns=['line_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.084621Z",
     "end_time": "2023-04-28T15:42:45.221420Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_line_type(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение категорий товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "cats = pd.read_csv('datasets/ProductsModels.csv')\n",
    "cats = cats.rename(columns={'model_id': 'category_id', 'name': 'category_name'})\n",
    "cats['new_id'] = cats.index\n",
    "cats.to_csv(DATASETS_PATH + 'categories_id.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.089653Z",
     "end_time": "2023-04-28T15:42:46.799055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.089737Z",
     "end_time": "2023-04-28T15:42:46.804003Z"
    }
   },
   "outputs": [],
   "source": [
    "def include_categories(data, cats_path='datasets/ProductsModels.csv'):\n",
    "    cats_new = cats.drop(columns=['category_name', 'category_id']).rename(columns={'new_id': 'category_id'})\n",
    "    data = data.join(cats_new.set_index('product_id'), on='product_id', how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.089777Z",
     "end_time": "2023-04-28T15:42:46.808205Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = include_categories(data, 'datasets/ProductsModels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление дней недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.094911Z",
     "end_time": "2023-04-28T15:42:46.812284Z"
    }
   },
   "outputs": [],
   "source": [
    "def include_weekday(data):\n",
    "    # print('Including weekdays')\n",
    "    def get_weekday(datetime):\n",
    "        return datetime.weekday()\n",
    "\n",
    "    weekdays = data['datetime'].apply(get_weekday)\n",
    "    data['weekday'] = weekdays\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.094988Z",
     "end_time": "2023-04-28T15:42:46.816630Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = include_weekday(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка всего набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс для ключей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.104133Z",
     "end_time": "2023-04-28T15:42:46.855626Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeyDict:\n",
    "    def __init__(self):\n",
    "        self.max = 0\n",
    "        self.dict = {}\n",
    "\n",
    "    def push(self, obj):\n",
    "        if obj in self.dict:\n",
    "            return self.dict[obj]\n",
    "        self.dict[obj] = self.max\n",
    "        self.max += 1\n",
    "        return self.max - 1\n",
    "\n",
    "    def get(self, obj):\n",
    "        if obj not in self.dict:\n",
    "            return None\n",
    "        return self.dict[obj]\n",
    "\n",
    "    def save(self, path):\n",
    "        with open(path, 'w') as file:\n",
    "            file.write(json.dumps(self.dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.104232Z",
     "end_time": "2023-04-28T15:42:46.856103Z"
    }
   },
   "outputs": [],
   "source": [
    "NROWS = 1_000_000\n",
    "BATCH_SIZE = 500_000\n",
    "PATH = 'datasets/receipts_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    time_batch_0 = time.perf_counter()\n",
    "    batch = collapse(batch)\n",
    "    batch = transform_transaction_key(batch)\n",
    "    batch = transform_gid(batch)\n",
    "    batch = transform_line_type(batch)\n",
    "    batch = include_categories(batch, 'datasets/ProductsModels.csv')\n",
    "    batch = include_weekday(batch)\n",
    "\n",
    "    time_batch_delta = time.perf_counter() - time_batch_0\n",
    "    print('Batch time - {.3f}s'.format(time_batch_delta))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def process_data(batch_size=BATCH_SIZE, path=PATH):\n",
    "    batches = []\n",
    "\n",
    "    def concat_batches(batch):\n",
    "        nonlocal batches\n",
    "        batches.append(batch)\n",
    "\n",
    "    data = pd.read_csv(path, nrows=NROWS)\n",
    "    data = data.rename(columns={'line_item_id': 'product_id'}).drop(columns=['opened_date', 'line_margin'])\n",
    "\n",
    "    print('Data has been read with {} rows'.format(data.shape[0]))\n",
    "    print('Batching with {} batch size, {} batches count'.format(BATCH_SIZE, math.ceil(data.shape[0] / batch_size)))\n",
    "    print('Running multiprocessing with {} cpu units...'.format(multiprocessing.cpu_count()))\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "    for batch in np.array_split(data, data.shape[0] / batch_size):\n",
    "        pool.apply_async(\n",
    "            process_batch,\n",
    "            args=(batch,),\n",
    "            callback=concat_batches\n",
    "        )\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "    data = pd.concat(batches, ignore_index=True, sort=False)\n",
    "    data = data.rename(columns = {'key_id': 'transaction_key'})\n",
    "    print('Collapsing all batches...')\n",
    "    data = collapse(data)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.104274Z",
     "end_time": "2023-04-28T15:42:46.856337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "weekdays_id = KeyDict()\n",
    "weekdays_id.push('Воскресенье')\n",
    "weekdays_id.push('Понедельник')\n",
    "weekdays_id.push('Вторник')\n",
    "weekdays_id.push('Среда')\n",
    "weekdays_id.push('Четверг')\n",
    "weekdays_id.push('Пятница')\n",
    "weekdays_id.push('Суббота')\n",
    "weekdays_id.save(DICTS_PATH + 'weekdays.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T15:42:45.104310Z",
     "end_time": "2023-04-28T15:42:46.856505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T14:00:38.928435Z",
     "end_time": "2023-04-28T14:03:42.060088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been read with 27601042 rows\n",
      "Batching with 500000 batch size, 56 batches count\n",
      "Running multiprocessing with 16 cpu units...\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "time_0 = time.perf_counter()\n",
    "\n",
    "trans_id, gids_id, lines_id = KeyDict(), KeyDict(), KeyDict()\n",
    "\n",
    "data_processed = process_data()\n",
    "time_delta = time.perf_counter() - time_0\n",
    "print('Overall time - {.3f}s'.format(time_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_processed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T14:03:42.059965Z",
     "end_time": "2023-04-28T14:03:42.060396Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-28T14:03:42.060057Z",
     "end_time": "2023-04-28T14:05:43.863191Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_id.save(DICTS_PATH + 'transaction_keys.json')\n",
    "gids_id.save(DICTS_PATH + 'gids.json')\n",
    "lines_id.save(DICTS_PATH + 'type_lines.json')\n",
    "save(data_processed, 'data_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
