{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.307450892Z",
     "start_time": "2023-05-17T11:22:37.245418241Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.315700429Z",
     "start_time": "2023-05-17T11:22:37.254359987Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helper import KeyDict, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.370037280Z",
     "start_time": "2023-05-17T11:22:37.259035927Z"
    }
   },
   "outputs": [],
   "source": [
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "DICTS_PATH = 'out/dicts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.393223249Z",
     "start_time": "2023-05-17T11:22:37.262655872Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/receipts_new.csv', nrows=5_000_000)\n",
    "# data = data.rename(columns = {'line_item_id': 'product_id'})\n",
    "# data\n",
    "# data.head(1000).to_csv('datasets/receipts_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.393994230Z",
     "start_time": "2023-05-17T11:22:37.266652125Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что совпадают некоторые строки по ключевому признаку - transaction_key, необходимо произвести схлопывание данных по одинаковым ключам с суммированием признаков line_quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение обработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.396849587Z",
     "start_time": "2023-05-17T11:22:37.270563597Z"
    }
   },
   "outputs": [],
   "source": [
    "# def save(data, name):\n",
    "#     print('SAVING dataset: {}\\n'.format(name.upper()))\n",
    "#     data.info(memory_usage='deep')\n",
    "#     data.to_csv(DATASETS_PATH + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Схлопывание одинаковых позиций в чеках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.398007416Z",
     "start_time": "2023-05-17T11:22:37.275081385Z"
    }
   },
   "outputs": [],
   "source": [
    "def collapse(data):\n",
    "    # print('Collapsing data')\n",
    "    grouped_series = data[['transaction_key', 'product_id', 'line_quantity']].groupby(\n",
    "        by=['transaction_key', 'product_id'])['line_quantity'].sum()\n",
    "\n",
    "    # data = data.groupby(by=['transaction_key', 'product_id']).first().reset_index()\n",
    "\n",
    "    data = data.join(grouped_series, how='left', on=['transaction_key', 'product_id'], lsuffix='_old')\n",
    "    data = data.drop(columns=['line_quantity_old'])\n",
    "    return data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.399295162Z",
     "start_time": "2023-05-17T11:22:37.279635172Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = collapse(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование transaction_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.402102687Z",
     "start_time": "2023-05-17T11:22:37.286133548Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(str):\n",
    "    return str.split('_')[3:4][0]\n",
    "\n",
    "\n",
    "def get_key(str):\n",
    "    splitted = str.split('_')\n",
    "    ans = ''\n",
    "    for i in range(3):\n",
    "        ans += splitted[i]\n",
    "    ans += splitted[-1]\n",
    "    return int(ans)\n",
    "\n",
    "\n",
    "def transform_transaction_key(data, trans_id):\n",
    "    # global trans_id\n",
    "    # print('Transforming dates')\n",
    "    dates = data['transaction_key'].apply(get_data)\n",
    "    dates = pd.to_datetime(dates)\n",
    "    data['datetime'] = dates\n",
    "\n",
    "    data['transaction_key'] = data['transaction_key'].apply(lambda x: trans_id.get(x))\n",
    "    return data\n",
    "    # print('Transforming keys')\n",
    "    # keys = data['transaction_key']\n",
    "    # keys = keys.drop_duplicates()\n",
    "    # keys = keys.to_frame()\n",
    "    #\n",
    "    # for ind, key in keys.iterrows():\n",
    "    #     keys.at[ind, 'key_id'] = trans_id.push(key['transaction_key'])\n",
    "    #\n",
    "    # data = data.join(keys.set_index('transaction_key'), how='left', on='transaction_key')\n",
    "    # data = data.drop(columns=['transaction_key'])\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403647093Z",
     "start_time": "2023-05-17T11:22:37.333045506Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_transaction_key(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование gid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403723259Z",
     "start_time": "2023-05-17T11:22:37.333227854Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_gid(data, gids_id):\n",
    "    data['gid'] = data['gid'].apply(lambda x: gids_id.get(x))\n",
    "    return data\n",
    "    # print('Transforming gid')\n",
    "    # gids = data['gid']\n",
    "    # gids = gids.drop_duplicates()\n",
    "    # gids = gids.to_frame()\n",
    "    #\n",
    "    # for ind, gid in gids.iterrows():\n",
    "    #     gids.at[ind, 'gid_id'] = gids_id.push(gid['gid'])\n",
    "    #\n",
    "    # data = data.join(gids.set_index('gid'), on='gid', how='left')\n",
    "    # return data.drop(columns=['gid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403774526Z",
     "start_time": "2023-05-17T11:22:37.333336912Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_gid(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Преобразование product_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def transform_product_id(data, products_id):\n",
    "    data['product_id'] = data['product_id'].apply(lambda x: products_id.get(x))\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403835653Z",
     "start_time": "2023-05-17T11:22:37.333436371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403884346Z",
     "start_time": "2023-05-17T11:22:37.333536372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование line_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403928670Z",
     "start_time": "2023-05-17T11:22:37.333638317Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_line_type(data, lines_id):\n",
    "    # print('Transforming line_type')\n",
    "    data['line_type'] = data['line_type'].apply(lambda x: lines_id.get(x))\n",
    "    return data\n",
    "    # line_types = data['line_type']\n",
    "    # line_types = line_types.drop_duplicates()\n",
    "    # line_types = line_types.to_frame()\n",
    "    #\n",
    "    # for ind, line_type in line_types.iterrows():\n",
    "    #     line_types.at[ind, 'line_type_id'] = lines_id.push(line_type['line_type'])\n",
    "    #\n",
    "    # data = data.join(line_types.set_index('line_type'), on='line_type', how='left')\n",
    "    # return data.drop(columns=['line_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:37.403972384Z",
     "start_time": "2023-05-17T11:22:37.333764948Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = transform_line_type(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение категорий товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "cats = pd.read_csv('datasets/ProductsModels.csv')\n",
    "cats = cats.rename(columns={'model_id': 'category_id', 'name': 'category_name'})\n",
    "cats['new_id'] = cats.index\n",
    "cats.to_csv(DATASETS_PATH + 'categories_id.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.069927166Z",
     "start_time": "2023-05-17T11:22:37.333864668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.121265608Z",
     "start_time": "2023-05-17T11:22:39.075713734Z"
    }
   },
   "outputs": [],
   "source": [
    "def include_categories(data):\n",
    "    cats_new = cats.drop(columns=['category_name', 'category_id']).rename(columns={'new_id': 'category_id'})\n",
    "    data = data.join(cats_new.set_index('product_id'), on='product_id', how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.127930582Z",
     "start_time": "2023-05-17T11:22:39.121422657Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = include_categories(data, 'datasets/ProductsModels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление дней недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.128103241Z",
     "start_time": "2023-05-17T11:22:39.121535743Z"
    }
   },
   "outputs": [],
   "source": [
    "def include_weekday(data):\n",
    "    # print('Including weekdays')\n",
    "    def get_weekday(datetime):\n",
    "        return datetime.weekday()\n",
    "\n",
    "    weekdays = data['datetime'].apply(get_weekday)\n",
    "    data['weekday'] = weekdays\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.128154910Z",
     "start_time": "2023-05-17T11:22:39.121620434Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = include_weekday(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка всего набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс для ключей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.128199795Z",
     "start_time": "2023-05-17T11:22:39.121701108Z"
    }
   },
   "outputs": [],
   "source": [
    "# class KeyDict:\n",
    "#     def __init__(self, name='Default'):\n",
    "#         self.name = name\n",
    "#         self.max = 0\n",
    "#         self.dict = {}\n",
    "#\n",
    "#     def push(self, obj):\n",
    "#         if obj in self.dict:\n",
    "#             return self.dict[obj]\n",
    "#         self.dict[obj] = self.max\n",
    "#         self.max += 1\n",
    "#         return self.max - 1\n",
    "#\n",
    "#     def get(self, obj):\n",
    "#         if obj not in self.dict:\n",
    "#             return None\n",
    "#         return self.dict[obj]\n",
    "#\n",
    "#     def save(self, path):\n",
    "#         print(len(self.dict))\n",
    "#         with open(path, 'w') as file:\n",
    "#             file.write(json.dumps(self.dict))\n",
    "#\n",
    "#     def load(self, path):\n",
    "#         with open(path) as json_file:\n",
    "#             self.dict = json.load(json_file)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.128243629Z",
     "start_time": "2023-05-17T11:22:39.121792984Z"
    }
   },
   "outputs": [],
   "source": [
    "NROWS = 10_000_000\n",
    "BATCH_SIZE = 250_000\n",
    "PATH = 'datasets/receipts_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.128290268Z",
     "start_time": "2023-05-17T11:22:39.121904106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "def process_data(batch_size=BATCH_SIZE, path=PATH):\n",
    "    batches = []\n",
    "\n",
    "    data = pd.read_csv(path, nrows=NROWS)\n",
    "    print('Data has been read with {} rows'.format(data.shape[0]))\n",
    "\n",
    "    data = data.rename(columns={'line_item_id': 'product_id'}).drop(columns=['opened_date', 'line_margin'])\n",
    "\n",
    "    print('Collecting key-dictionaries...')\n",
    "\n",
    "    def process_dict(data_column):\n",
    "        dict = KeyDict()\n",
    "        for row in data_column.drop_duplicates():\n",
    "            dict.push(row)\n",
    "        return dict\n",
    "\n",
    "    trans_id = process_dict(data['transaction_key'])\n",
    "    gids_id = process_dict(data['gid'])\n",
    "    lines_id = process_dict(data['line_type'])\n",
    "    products_id = process_dict(data['product_id'])\n",
    "\n",
    "    def concat_batches(batch):\n",
    "        nonlocal batches\n",
    "        batches.append(batch)\n",
    "\n",
    "    print('Batching with {} batch size, {} batches count'.format(BATCH_SIZE, math.ceil(data.shape[0] / batch_size)))\n",
    "\n",
    "    # print('Running multiprocessing with {} cpu units...'.format(multiprocessing.cpu_count()))\n",
    "\n",
    "    def process_batch(batch):\n",
    "        time_batch_0 = time.perf_counter()\n",
    "        batch = collapse(batch)\n",
    "        batch = transform_transaction_key(batch, trans_id)\n",
    "        batch = transform_gid(batch, gids_id)\n",
    "        batch = transform_line_type(batch, lines_id)\n",
    "        batch = transform_product_id(batch, products_id)\n",
    "        batch = include_categories(batch)\n",
    "        batch = include_weekday(batch)\n",
    "        time_batch_delta = time.perf_counter() - time_batch_0\n",
    "        # print('Batch time - {:.3f}s'.format(time_batch_delta))\n",
    "        return batch\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "    for batch in tqdm(np.array_split(data, data.shape[0] / batch_size)):\n",
    "        batch = process_batch(batch)\n",
    "        concat_batches(batch)\n",
    "        # pool.apply_async(\n",
    "        #     process_batch,\n",
    "        #     args=(batch,),\n",
    "        #     callback=concat_batches\n",
    "        # )\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    data = pd.concat(batches, ignore_index=True, sort=False)\n",
    "    data = data.rename(columns={'key_id': 'transaction_key'})\n",
    "    print('Collapsing all batches...')\n",
    "    data = collapse(data)\n",
    "\n",
    "    return data, trans_id, gids_id, lines_id, products_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T11:22:39.169307642Z",
     "start_time": "2023-05-17T11:22:39.168984856Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-17T11:22:39.169451686Z"
    }
   },
   "outputs": [],
   "source": [
    "time_0 = time.perf_counter()\n",
    "\n",
    "data_processed, trans_id, gids_id, lines_id, products_id = process_data()\n",
    "time_delta = time.perf_counter() - time_0\n",
    "print('Overall time - {:.3f}s'.format(time_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_processed"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "trans_id.save(DICTS_PATH + 'transaction_keys.json')\n",
    "gids_id.save(DICTS_PATH + 'gids.json')\n",
    "lines_id.save(DICTS_PATH + 'type_lines.json')\n",
    "products_id.save(DICTS_PATH + 'products.json')\n",
    "\n",
    "save(data_processed, 'data_processed.csv', DATASETS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
