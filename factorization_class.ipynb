{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "FIGURES_PATH = 'out/figures/'\n",
    "DATASETS_PATH = 'out/datasets/'\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocesspandas import applyparallel\n",
    "from pandarallel import pandarallel\n",
    "import psutil\n",
    "from sys import getsizeof\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "tqdm.pandas()\n",
    "from helper import *\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T17:49:32.893595584Z",
     "start_time": "2023-06-02T17:49:31.957570190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T17:49:32.922887434Z",
     "start_time": "2023-06-02T17:49:32.905673397Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# NROWS = 1_000_000\n",
    "# data = pd.read_csv(DATASETS_PATH + 'data_processed.csv', nrows=NROWS).drop(columns=['Unnamed: 0'])\n",
    "# data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "class Distances:\n",
    "    def __init__(self, data_path='data_processed', nrows=None):\n",
    "        \"\"\"\n",
    "        Initialize Distances class with the data\n",
    "\n",
    "        :param data_path: name of file\n",
    "        :param nrows: number of rows to read\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(DATASETS_PATH + data_path + '.csv', nrows=nrows).drop(columns=['Unnamed: 0'])\n",
    "        self.data['datetime'] = pd.to_datetime(self.data['datetime'])\n",
    "        self.nrows = nrows\n",
    "\n",
    "    @staticmethod\n",
    "    def save_dists(file, path):\n",
    "        with open(DATASETS_PATH + path + '.pkl', 'wb') as f:\n",
    "            pickle.dump(file, f)\n",
    "\n",
    "    def user_product(self):\n",
    "        \"\"\"\n",
    "        Get distances between all pairs of users by counting purchases\n",
    "\n",
    "        :return: dict[user] = {product: count}\n",
    "        \"\"\"\n",
    "\n",
    "        def process_batch(x):\n",
    "            ans = dict()\n",
    "            for i in x['product_id'].values:\n",
    "                if i in ans:\n",
    "                    ans[i] += 1\n",
    "                else:\n",
    "                    ans[i] = 1\n",
    "            return ans\n",
    "\n",
    "        data = self.data[['gid', 'product_id']]\n",
    "        pandarallel.initialize(progress_bar=True, use_memory_fs=True, nb_workers=psutil.cpu_count(logical=False))\n",
    "        ans = data.groupby(by='gid').parallel_apply(process_batch)\n",
    "\n",
    "        self.save_dists(ans, 'up_' + str(self.nrows))\n",
    "        return ans\n",
    "\n",
    "    def product_product(self, interval=None, batch_size=100_000):\n",
    "        \"\"\"\n",
    "        Get distances between all pairs of products by date differences\n",
    "        Считаем по каждому пользователю ближайшие (по модулю даты) покупки товаров.\n",
    "        Усредняем значения по каждому пользователю.\n",
    "\n",
    "        :param interval: date interval to split data with, default: None\n",
    "        :param batch_size: data batching size, default: 100_000\n",
    "        :return: dict[(product_1, product_2)] = an array of mean of date distance by one user\n",
    "        \"\"\"\n",
    "        ans = dict()\n",
    "\n",
    "        def data_splitting(interval):\n",
    "            nonlocal data\n",
    "            batches = []\n",
    "            data = data.sort_values(by='datetime')\n",
    "            start = data.iloc[0].at['datetime']\n",
    "            end = data.iloc[-1].at['datetime']\n",
    "            while start <= end:\n",
    "                sub_end = start + timedelta(days=interval)\n",
    "                batch = data.loc[data['datetime'] >= start].loc[data['datetime'] < sub_end]\n",
    "                batches.append(batch)\n",
    "                start = sub_end\n",
    "\n",
    "            return batches\n",
    "\n",
    "        def fill_ans(x):\n",
    "            product_date = x[['product_id', 'datetime']]\n",
    "            res = dict()\n",
    "            for i1, r1 in product_date.iterrows():\n",
    "                for i2, r2 in product_date.iterrows():\n",
    "                    if i1 != i2:\n",
    "                        p1, p2 = r1['product_id'], r2['product_id']\n",
    "                        timedelta = (r1['datetime'] - r2['datetime']).days\n",
    "\n",
    "                        if (p1, p2) in res and abs(res[(p1, p2)]) > abs(timedelta):\n",
    "                            res[(p1, p2)] = timedelta\n",
    "                        else:\n",
    "                            res[(p1, p2)] = timedelta\n",
    "            return res\n",
    "\n",
    "        def concat_dicts(res):\n",
    "            nonlocal ans\n",
    "            res = res.values\n",
    "            for r in res:\n",
    "                for key in r.keys():\n",
    "                    if key in ans:\n",
    "                        ans[key].append(r[key])\n",
    "                    else:\n",
    "                        ans[key] = [r[key]]\n",
    "            return ans\n",
    "\n",
    "        data = self.data[['gid', 'product_id', 'datetime']]\n",
    "        data.loc[:, 'datetime'] = data['datetime'].dt.date\n",
    "\n",
    "        if interval is not None:\n",
    "            batches = data_splitting(interval=interval)\n",
    "        else:\n",
    "            batches = np.array_split(data, data.shape[0] // batch_size + 1)\n",
    "\n",
    "        pandarallel.initialize(progress_bar=False, use_memory_fs=True, nb_workers=psutil.cpu_count(logical=False) // 2)\n",
    "\n",
    "        for batch in tqdm(batches):\n",
    "            if psutil.virtual_memory().percent >= 90:\n",
    "                break\n",
    "            grouped_by_user = batch.groupby(by='gid')\n",
    "            temp = grouped_by_user.parallel_apply(fill_ans)\n",
    "            temp = temp.dropna()\n",
    "            ans = concat_dicts(temp)\n",
    "\n",
    "        self.save_dists(ans, 'pp_' + str(self.nrows))\n",
    "        return ans\n",
    "\n",
    "    def get_up_matrix(self, num_users=50_000, num_products=10_000, batch_size=100_000):\n",
    "        def fill_ans(x):\n",
    "            nonlocal ans\n",
    "            user, product = x[0], x[1]\n",
    "            if user >= num_users or product >= num_products:\n",
    "                return\n",
    "            ans[user, product] += 1\n",
    "\n",
    "        data = self.data[['gid', 'product_id']]\n",
    "        # users = data['gid'].drop_duplicates().values\n",
    "        # print(users)\n",
    "        # products = data['product_id'].drop_duplicates().values\n",
    "        # print(products)\n",
    "        # # users = users.sort()\n",
    "        # # return users\n",
    "        # #\n",
    "        ans = np.full((num_users, num_products), 0)\n",
    "        # pandarallel.initialize(progress_bar=True)\n",
    "        #\n",
    "        for batch in tqdm(np.array_split(data, data.shape[0] // batch_size)):\n",
    "            batch.apply(fill_ans, axis=1)\n",
    "\n",
    "        self.save_dists(ans, 'up_matrix')\n",
    "        return ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "d = Distances(nrows=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T17:49:58.193529118Z",
     "start_time": "2023-06-02T17:49:32.917739336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "up = d.get_up_matrix(80_000, 50_000)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-02T17:49:58.257115931Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(up[:10, :10])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
